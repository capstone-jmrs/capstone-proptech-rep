{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import math \n",
    "\n",
    "from sql_functions import *    \n",
    "\n",
    "import psycopg2    \n",
    "\n",
    "# create global list of targeted neighbourhoods AND match with platform location IDs\n",
    "neighbourhoods = ['Hammersmith and Fulham', 'Kensington and Chelsea', 'Camden', 'City of Westminster', 'City of London', 'Hackney', 'Lambeth', 'Tower of Hamlets', 'Islington']\n",
    "rightmove_loc_id = ['5E61407', '5E61229', '5E93941', '5E61233', '5E61224', '5E93953', '5E93971', '5E61417', '5E93965']\n",
    "zip_iterator = zip(rightmove_loc_id, neighbourhoods)\n",
    "locations_dict = dict(zip_iterator)\n",
    "    # {\n",
    "    # '5E61407': 'Hammersmith and Fulham',\n",
    "    # '5E61229': 'Kensington and Chelsea',\n",
    "    # '5E93941': 'Camden',\n",
    "    # '5E61233': 'City of Westminster',\n",
    "    # '5E61224': 'City of London',\n",
    "    # '5E93953': 'Hackney',\n",
    "    # '5E93971': 'Lambeth',\n",
    "    # '5E61417': 'Tower of Hamlets',\n",
    "    # '5E93965': 'Islington'\n",
    "    # }\n",
    "\n",
    "################furnishTypes_lst = ['furnished', 'unfurnished', 'partFurnished']   # partFurnished gives back more than delta\n",
    "\n",
    "#---------------------------------------------\n",
    "\n",
    "# get internal IDs\n",
    "def get_ids_rm(bs):\n",
    "    ids = bs.find_all(class_ = 'l-searchResult is-list')\n",
    "    ids_lst = [id.get('id') for id in ids]\n",
    "    ids_lst = [(str(x)) for x in ids_lst]\n",
    "    return(ids_lst)\n",
    "# ids_lst\n",
    "\n",
    "#------------------------- new new\n",
    "#-------------------------\n",
    "\n",
    "# get property type\n",
    "def get_property_type_rm(bs):\n",
    "    types_lst = [title.text.strip().split()[-1] for title in bs.findAll('h2', {'class': 'propertyCard-title'})]\n",
    "    return(types_lst)\n",
    "\n",
    "\n",
    "# get number of bedrooms\n",
    "def get_bedrooms_rm(bs):\n",
    "    bedrooms_lst = [title.text.split('bedroom')[0].strip() for title in bs.findAll('h2', {'class': 'propertyCard-title'})]\n",
    "    return(bedrooms_lst)\n",
    "\n",
    "# get number of bathrooms\n",
    "def get_bathrooms_rm(bs):\n",
    "    bathrooms = bs.find_all(class_= \"propertyCard-features\")\n",
    "    bathrooms_lst = [bathroom.get_text() for bathroom in bathrooms]\n",
    "    bathrooms_lst = list(filter(None, bathrooms_lst)) #delete any empty strings from list\n",
    "    # format bathrooms\n",
    "    bathrooms_lst = [bathroom.split('bathroom')[0].strip() for bathroom in bathrooms_lst]\n",
    "    return(bathrooms_lst)\n",
    "\n",
    "\n",
    "# function for prices monthly and weekly(=sec_prices)\n",
    "def get_prices_rm(bs):\n",
    "    prices = bs.find_all(class_= \"propertyCard-priceValue\")\n",
    "    prices_lst = [price.get_text() for price in prices]\n",
    "    prices_lst = list(filter(None, prices_lst)) #delete any empty strings from list\n",
    "    # format prices\n",
    "    prices_lst = [price.removesuffix(' pcm').replace('£', '').replace(',', '') for price in prices_lst]\n",
    "    #prices_lst = [float(price) for price in prices_lst] #comment out to avoid error when no price is found or when price is not a number(\"POA\")\n",
    "    \n",
    "    return(prices_lst)  \n",
    "\n",
    "\n",
    "# def get_sec_prices_rm(bs):\n",
    "#     sec_prices = bs.find_all(class_= \"propertyCard-secondaryPriceValue\")\n",
    "#     sec_prices_lst = [sec_price.get_text() for sec_price in sec_prices]\n",
    "#     sec_prices_lst = list(filter(None, sec_prices_lst)) #delete any empty strings from list\n",
    "#     #format sec_prices\n",
    "#     sec_prices_lst = [sec_price.removesuffix(' pw').replace('£', '').replace(',', '') for sec_price in sec_prices_lst]\n",
    "#     #sec_prices_lst = [float(sec_price) for sec_price in sec_prices_lst]\n",
    "#     return(sec_prices_lst)\n",
    "\n",
    "#---------------------------------------------\n",
    "\n",
    "def page_results(loc_id, furniture):\n",
    "    # get content from immo website; create souppr\n",
    "    page = requests.get(\n",
    "        \"https://www.rightmove.co.uk/property-to-rent/find.html?locationIdentifier=REGION%{}&index={}&propertyTypes=&includeLetAgreed=false&mustHave=&dontShow=houseShare%2Cretirement%2Cstudent&furnishTypes={}&keywords=\".format(loc_id, '0', furniture))\n",
    "    html = page.content\n",
    "    bs = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # get number of search results\n",
    "    num_results = bs.find(class_=\"searchHeader-resultCount\").get_text()\n",
    "    num_results = num_results.replace(',', '')\n",
    "    num_results = int(num_results)\n",
    "    num_pages = math.ceil(num_results / 24) # don't know why, but have to use 24 instead of 25 (results per page)\n",
    "\n",
    "    # list of page indices we can use for the url to check every single page of search results\n",
    "    page_indices = [x*24 for x in range(0, num_pages)]\n",
    "\n",
    "    # ...\n",
    "    df_search_rm = pd.DataFrame()\n",
    "\n",
    "    for page_number in page_indices:\n",
    "        # ...\n",
    "        page = requests.get(\n",
    "            \"https://www.rightmove.co.uk/property-to-rent/find.html?locationIdentifier=REGION%{}&index={}&propertyTypes=&includeLetAgreed=false&mustHave=&dontShow=houseShare%2Cretirement%2Cstudent&keywords=\".format(loc_id, page_number))\n",
    "        html = page.content\n",
    "        bs = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        # Create a dictionary to store the results from every loop cycle.\n",
    "        # The keys are the column names and the values are the functions we created before.\n",
    "        # The functions are called with the beautiful soup object as a parameter.\n",
    "        rightmove_dict = {\n",
    "            'platform_id': get_ids_rm(bs)\n",
    "            ,'platform': 'Rightmove'\n",
    "            ,'neighbourhood': locations_dict[loc_id]\n",
    "            ,'property_type': get_property_type_rm(bs)\n",
    "            ,'bedrooms': get_bedrooms_rm(bs)\n",
    "            #,'bathrooms': get_bathrooms_rm(bs)\n",
    "                        ,'prices_pcm': get_prices_rm(bs)\n",
    "            #,'title': get_title_rm(bs)\n",
    "            #,'furniture': furniture    ########### avoid duplicates in the first place\n",
    "            #,'furniture': get_furniture_rm(bs)\n",
    "            #,'available_from': get_available_from_rm(bs)\n",
    "            #,'size': get_size_rm(bs)\n",
    "            #,'scraping_date': datetime.today().strftime('%Y-%m-%d')\n",
    "            #,\n",
    "            }\n",
    "        \n",
    "        # dictionary is stored in a 'temporary' dataframe within (each) loop cycle\n",
    "        df_page_rm = pd.DataFrame(rightmove_dict)\n",
    "\n",
    "        # the temporary dataframe is appended to the dataframe we set up before the loop\n",
    "        df_search_rm = pd.concat([df_search_rm, df_page_rm], ignore_index=True)\n",
    "\n",
    "    # the data frame search gets returned to the for loop to access it outside the function\n",
    "    return(df_search_rm)\n",
    "\n",
    "# see above: furnishTypes_lst = ['furnished', 'unfurnished', 'partFurnished']\n",
    "# see above: rightmove_loc_id = ['5E61407', '5E61229', '5E93941', '5E61233', '5E61224', '5E93953', '5E93971', '5E61417', '5E93965']\n",
    "\n",
    "#------------------------------------------------------------\n",
    "#------------------------------------------------------------\n",
    "\n",
    "# set up empty dataframe\n",
    "df_complete_rm = pd.DataFrame()\n",
    "\n",
    "for loc_id in rightmove_loc_id:\n",
    "    df_complete_rm = pd.concat([df_complete_rm, page_results(loc_id)], ignore_index=True)\n",
    "\n",
    "# append column with today's date  \n",
    "df_complete_rm['scraping_date'] = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "#------------------------------------------------------------\n",
    "#------------------------------------------------------------\n",
    "\n",
    "# Drop IDs that are not unique\n",
    "df_complete_rm.drop_duplicates(subset = ['platform_id'], inplace = True)\n",
    "\n",
    "# convert/clean platform_id\n",
    "df_complete_rm['platform_id'] = df_complete_rm['platform_id'].removeprefix('property-')#.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rightmove_1 table was imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# import the data frame to DBeaver\n",
    "\n",
    "# call the schema created for this project\n",
    "schema = 'capstone_jmrs'\n",
    "# get the function to connect to the database\n",
    "engine = get_engine()\n",
    "\n",
    "# give the table a unique name\n",
    "table_name = 'rightmove_1'\n",
    "\n",
    "# import the table to sql\n",
    "if engine!=None:\n",
    "    try:\n",
    "        df_complete_rm.to_sql(name=table_name,\n",
    "                        con=engine,\n",
    "                        if_exists='replace',\n",
    "                        schema=schema, \n",
    "                        index=False,\n",
    "                        chunksize=5000, \n",
    "                        method='multi')\n",
    "        print(f\"The {table_name} table was imported successfully.\")\n",
    "    \n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        engine = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detail Pages \n",
    "## important: still need to implement correct order of im-/exporting from/to Database!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of platform_ids from DBeaver first\n",
    "\n",
    "schema = 'capstone_jmrs'\n",
    "\n",
    "sql = f\"\"\"\n",
    "SELECT platform_id \n",
    "FROM {schema}.rightmove_3\n",
    "\"\"\"\n",
    "\n",
    "df = get_dataframe(sql)\n",
    "ids = df['platform_id'].tolist()\n",
    "\n",
    "#df_details_complete = pd.DataFrame()\n",
    "#df_basics_complete = pd.DataFrame()\n",
    "\n",
    "#------------------------------------------------------------\n",
    "### START OF LOOP ###\n",
    "#------------------------------------------------------------\n",
    "for id in ids:\n",
    "    time.sleep(random.randint(2,5)/10)\n",
    "    \n",
    "    # get content of detail website\n",
    "    page = requests.get(f\"https://www.rightmove.co.uk/properties/{id}#/?channel=RES_LET\")\n",
    "    html = page.content\n",
    "    bs = BeautifulSoup(html, 'html.parser')\n",
    "#------------------------------------------------------------\n",
    "# Part A: details\n",
    "    # set up dictionary for details; fill with default values if particular detail not available on website\n",
    "    bedrooms, bathrooms, size, property_type = 'NA', 'NA', 'NA', 'NA' \n",
    "    row_dict = {'property_id':id, 'bedrooms': bedrooms, 'bathrooms': bathrooms, 'size': size, 'property_type': property_type}\n",
    "\n",
    "    # get property details via explicit class\n",
    "    details = bs.find(\n",
    "        'div', class_='_4hBezflLdgDMdFtURKTWh')\n",
    "\n",
    "    ## skip property if no details available (because property has already been removed); otherwise loop would break  \n",
    "    if details == None:\n",
    "        continue\n",
    "\n",
    "    # convert details to list\n",
    "    details_lst = (detail.get_text() for detail in details)\n",
    "    details_lst = [detail.strip() for detail in details_lst]\n",
    "\n",
    "\n",
    "    # loop through list and assign values to dictionary keys (necessary since list length is not fixed);\n",
    "    # if no value is available, the default value (NA) is kept\n",
    "    # (could also be done with try/except) ?!\n",
    "    for detail in details_lst:\n",
    "        if 'TYPE' in detail:\n",
    "            row_dict['property_type'] = detail.removeprefix('PROPERTY TYPE')\n",
    "        elif 'BEDROOMS' in detail:\n",
    "            row_dict['bedrooms'] = detail[-1]\n",
    "        elif 'BATHROOM' in detail:\n",
    "            row_dict['bathrooms'] = detail[-1]\n",
    "        elif 'SIZE' in detail:\n",
    "            row_dict['size'] = re.search(r'\\((.*?)\\)', str(detail)).group(1).removesuffix(' sq. m.').replace(',', '')\n",
    "    \n",
    "    # store in details dataframe for this explicit id\n",
    "    df_details = pd.DataFrame(row_dict, index=[0])\n",
    "\n",
    "    # append to complete details dataframe    \n",
    "    df_details_complete = pd.concat([df_details_complete, df_details], ignore_index=True)\n",
    "#------------------------------------------------------------\n",
    "# Part B: basics\n",
    "    # via another class: get other basic details, here called \"basics\" (Let available from, Furnished, Title, ...)\n",
    "    basics = bs.find_all(\n",
    "        'div', class_='_2RnXSVJcWbWv4IpBC1Sng6')\n",
    "\n",
    "    # convert basics to list\n",
    "    # like ['Let available from:  1st May 2021', 'Deposit: Ask agent...', 'Furnished: Furnished', ...]\n",
    "    basics_lst = (basic.get_text() for basic in basics)\n",
    "\n",
    "    # split list entries by ':' and strip whitespaces. This returns List(fixed? len=5) of Lists(fixed len=2)\n",
    "    # e.g. [['Let available from', ' 1st May 2021'], ['Deposit', 'Ask agent...'], ['Furnish Type', 'Furnished'], ...]\n",
    "    basics_lst = [basic.strip().split(': ') for basic in basics_lst]\n",
    "   \n",
    "    # writes basics_lst into dict like {'Let available from': '01/08/2021', 'Furnished': 'Unfurnished', 'Title': 'Flat', ...}\n",
    "    itemDict = {item[0]: item[1] for item in basics_lst}\n",
    "    # add explicit id value to dict\n",
    "    itemDict['platform_id'] = id\n",
    "\n",
    "    # store basics in dataframe for this explicit id\n",
    "    df_basics = pd.DataFrame(itemDict, index=[0])\n",
    "\n",
    "    # append id-specific df to df_basics_complete containing all of already looped properties\n",
    "    df_basics_complete = pd.concat([df_basics_complete, df_basics], ignore_index=True)\n",
    "#------------------------------------------------------------\n",
    "### END OF LOOP ###\n",
    "#------------------------------------------------------------\n",
    "\n",
    "# Part C:\n",
    "# drop columns from basics_df we don't need\n",
    "df_basics_complete.drop(['Deposit', 'Min. Tenancy', 'Council Tax'], axis=1, inplace=True)\n",
    "\n",
    "# pythonise column names \n",
    "df_basics_complete.columns.values[0:3] = ['available_from', 'let_type', 'furnished']\n",
    "\n",
    "# concatenate both details and basics df to new_df\n",
    "new_df = pd.concat([df_details_complete, df_basics_complete], axis=1)\n",
    "\n",
    "# add date of scraping\n",
    "new_df['scraping_date'] = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# drop duplicates\n",
    "new_df.drop_duplicates(inplace=True)\n",
    "\n",
    "\n",
    "# import the data frame to DBeaver\n",
    "# call the schema created for this project\n",
    "schema = 'capstone_jmrs'\n",
    "# get the function to connect to the database\n",
    "engine = get_engine()\n",
    "\n",
    "# give the table a unique name\n",
    "table_name = 'rightmove_details'\n",
    "\n",
    "# import the table to sql\n",
    "if engine!=None:\n",
    "    try:\n",
    "        new_df.to_sql(name=table_name,\n",
    "                        con=engine,\n",
    "                        if_exists='replace',\n",
    "                        schema=schema, \n",
    "                        index=False,\n",
    "                        chunksize=5000, \n",
    "                        method='multi')\n",
    "        print(f\"The {table_name} table was imported successfully.\")\n",
    "    \n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        engine = None\n",
    "\n",
    "# first run took approx 124minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Let available date': 'Ask agent',\n",
       " 'Deposit': 'Ask agentA deposit provides security for a landlord against damage, or unpaid rent by a tenant.Read more about deposit in our glossary page.',\n",
       " 'Min. Tenancy': 'Ask agentHow long the landlord offers to let the property for.Read more about tenancy length in our glossary page.',\n",
       " 'Let type': 'Long term',\n",
       " 'Furnish type': 'Furnished'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import time\n",
    "# import random\n",
    "\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# import pandas as pd\n",
    "# import re\n",
    "# import pandas as pd\n",
    "# from datetime import datetime\n",
    "# import math \n",
    "\n",
    "# from sql_functions import *    \n",
    "\n",
    "# import psycopg2    \n",
    "\n",
    "# page = requests.get(f\"https://www.rightmove.co.uk/properties/127325693#/?channel=RES_LET\")\n",
    "# html = page.content\n",
    "# bs = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "\n",
    "basics = bs.find_all(\n",
    "    'div', class_='_2RnXSVJcWbWv4IpBC1Sng6')\n",
    "\n",
    "# convert basics to list\n",
    "basics_lst = (basic.get_text() for basic in basics)\n",
    "# split list entries by ':' and strip whitespaces\n",
    "basics_lst = [basic.strip().split(': ') for basic in basics_lst]\n",
    "basics_lst\n",
    "itemDict = {item[0]: item[1] for item in basics_lst}\n",
    "itemDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new paragraph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('nf_sql')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a81d278bed5b5b59425dcb5a82ce505657686243c184b4a6b67e69d01c4d432e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
