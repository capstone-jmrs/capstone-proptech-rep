{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Notebook for Webscraping of Blueground\n",
    "\n",
    "Clean means: You can start from top an run to bottom without an error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the libraries\n",
    "\n",
    "import time # to pause the code\n",
    "import requests # to get the content of the website\n",
    "from bs4 import BeautifulSoup # to parse the html\n",
    "import re # to use regular expressions\n",
    "import pandas as pd # to use pandas\n",
    "import numpy as np # to use numpy\n",
    "import datetime as dt           # for the csv file with the current date and time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we create empty dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty dataframe\n",
    "df_full = pd.DataFrame()\n",
    "df_object = pd.DataFrame()\n",
    "df_search = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we set up the link and stuff for the loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test: Links: \n",
    "\n",
    "https://www.theblueground.com/furnished-apartments-london-uk?currency=GBP&language=en&offset=10&items=18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the link to the website\n",
    "\n",
    "weblink = 'https://www.theblueground.com/furnished-apartments-london-uk?currency=GBP&language=en&'\n",
    "\n",
    "# set up the first page to scrape\n",
    "pagesite = 10 # we set it to 10 to test the code\n",
    "\n",
    "# create an empty list to store the blank slates\n",
    "blank_slates_lst = [] \n",
    "\n",
    "# set the stop condition\n",
    "stop_loop = \"We’re sorry! We can’t seem to find any apartments that match your search.\" \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we need the following structure for the dataframe:\n",
    "+ platform_id\t\n",
    "+ platform\t\n",
    "+ neighbourhood\t\n",
    "+ property_type\t\n",
    "+ bedrooms\t\n",
    "+ bathroom\t\n",
    "+ price_pcm\t\n",
    "+ title\t\n",
    "+ furnished\t\n",
    "+ available_from\t\n",
    "+ size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of Neighbourhoods from Blueground\n",
    "\n",
    "bayswater\n",
    "bermondsey\n",
    "bromley-by-bow\n",
    "camden-town\n",
    "canary-wharf\n",
    "charing-cross\n",
    "chelsea\n",
    "city-of-london\n",
    "clerkenwell\n",
    "covent-garden\n",
    "croydon\n",
    "earls-court\n",
    "farringdon\n",
    "fitzrovia\n",
    "fulham\n",
    "hackney\n",
    "hammersmith\n",
    "highgate\n",
    "holborn\n",
    "islington\n",
    "kensington\n",
    "kentish-town\n",
    "kings-cross\n",
    "knightsbridge\n",
    "ladbroke-grove\n",
    "limehouse\n",
    "maida-vale\n",
    "marylebone\n",
    "mayfair\n",
    "notting-hill\n",
    "old-street\n",
    "paddington\n",
    "piccadilly\n",
    "pimlico\n",
    "queens-park\n",
    "shoreditch\n",
    "soho\n",
    "south-bank\n",
    "south-kensington\n",
    "southwark\n",
    "stockwell\n",
    "vauxhall\n",
    "walthamstow\n",
    "wandsworth\n",
    "wapping\n",
    "waterloo\n",
    "westminster\n",
    "whitechapel-brick-lane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we load all the functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "platform_id --> from Detail-Page --> currently not working\n",
    "we get the ID from the last part of the URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'get_url_to_detail_page'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/markussteinke/neuefische/capstone-ukio-rep/blueground_clean_markus.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/markussteinke/neuefische/capstone-ukio-rep/blueground_clean_markus.ipynb#X62sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m id_from_url \u001b[39m=\u001b[39m df_search\u001b[39m.\u001b[39;49mloc[\u001b[39m'\u001b[39;49m\u001b[39mget_url_to_detail_page\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/markussteinke/neuefische/capstone-ukio-rep/blueground_clean_markus.ipynb#X62sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m id_from_url\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/nf_bs4/lib/python3.9/site-packages/pandas/core/indexing.py:967\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    964\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m    966\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[0;32m--> 967\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/nf_bs4/lib/python3.9/site-packages/pandas/core/indexing.py:1202\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1200\u001b[0m \u001b[39m# fall thru to straight lookup\u001b[39;00m\n\u001b[1;32m   1201\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m-> 1202\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_label(key, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/nf_bs4/lib/python3.9/site-packages/pandas/core/indexing.py:1153\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_label\u001b[39m(\u001b[39mself\u001b[39m, label, axis: \u001b[39mint\u001b[39m):\n\u001b[1;32m   1152\u001b[0m     \u001b[39m# GH#5667 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[0;32m-> 1153\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49mxs(label, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/nf_bs4/lib/python3.9/site-packages/pandas/core/generic.py:3864\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3862\u001b[0m             new_index \u001b[39m=\u001b[39m index[loc]\n\u001b[1;32m   3863\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 3864\u001b[0m     loc \u001b[39m=\u001b[39m index\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3866\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(loc, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m   3867\u001b[0m         \u001b[39mif\u001b[39;00m loc\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mbool_:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/nf_bs4/lib/python3.9/site-packages/pandas/core/indexes/range.py:389\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    388\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m--> 389\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n\u001b[1;32m    390\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mget_loc(key, method\u001b[39m=\u001b[39mmethod, tolerance\u001b[39m=\u001b[39mtolerance)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'get_url_to_detail_page'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "platform --> we can add the Origin-Platform during the Loop, in this Notebook we have only \"blueground\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighborhoods(bs):\n",
    "    neighborhood_names = bs.find_all(\"div\", {\"class\":\"name-place\"})\n",
    "    neighborhood_names_lst = (neighborhood_name.get_text() for neighborhood_name in neighborhood_names)\n",
    "    neighborhood_names_lst = [neighborhood_name.strip() for neighborhood_name in neighborhood_names_lst]\n",
    "    neighborhood_names_lst = [i.rsplit(',', 1)[-1] for i in neighborhood_names_lst]\n",
    "    return neighborhood_names_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "property_type \n",
    "on Blueground their is only \"Studio\" or \"Apartment\"\n",
    "\n",
    "> later we have to change the Type  \"Jr. Bedroom\" to \"Studio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_property_type(bs):\n",
    "    # get the property_type out of the apartment amenities\n",
    "    lst_name = []\n",
    "    property_typs = bs.find_all(class_=\"main-amenities\")\n",
    "    property_typs_lst = [property_type.get_text() for property_type in property_typs]\n",
    "    property_typs_lst = [property_type.strip() for property_type in property_typs_lst]\n",
    "    property_typs_lst = [i.split('o', 1)[0] for i in property_typs_lst]\n",
    "    property_typs_lst = [i.replace('Bedr', 'Bedroom') for i in property_typs_lst]\n",
    "    property_typs_lst = [i.replace('Studi', 'Studio') for i in property_typs_lst]\n",
    "    property_typs_lst = [i.rsplit(' ', 1)[-1] for i in property_typs_lst]\n",
    "    #property_typs_lst = [i.replace('Bedroom', 'Apartment') for i in property_typs_lst]\n",
    "    return property_typs_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bedrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bedrooms(bs):\n",
    "    # get the main-amenities of the apartments\n",
    "    lst_name = []\n",
    "    bedrooms = bs.find_all(class_=\"main-amenities\")\n",
    "    bedrooms_lst = [bedroom.get_text() for bedroom in bedrooms]\n",
    "    bedrooms_lst = [bedroom.strip() for bedroom in bedrooms_lst]\n",
    "    bedrooms_lst = [i.split('o', 1)[0] for i in bedrooms_lst]\n",
    "    bedrooms_lst = [i.replace('Bedr', 'Bedroom') for i in bedrooms_lst]\n",
    "    bedrooms_lst = [i.replace('Studi', 'Studio') for i in bedrooms_lst]\n",
    "    return bedrooms_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bathroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bathroom(bs):\n",
    "    # get the main-amenities of the apartments\n",
    "    lst_name = []\n",
    "    bathrooms= bs.find_all(class_=\"main-amenities\")\n",
    "    bathrooms_lst = [bathroom.get_text() for bathroom in bathrooms]\n",
    "    bathrooms_lst = [bathroom.strip() for bathroom in bathrooms_lst]\n",
    "    bathrooms_lst = [i.rsplit('o', 1)[-1] for i in bathrooms_lst]\n",
    "    bathrooms_lst = [i.replace('m', '') for i in bathrooms_lst]\n",
    "\n",
    "    return bathrooms_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "price_pcm (price per month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_pcm(bs):\n",
    "    # get the price per month\n",
    "    lst_name = []\n",
    "    prices = bs.find_all(class_= \"price__amount\")\n",
    "    for price in prices:\n",
    "        lst_name.append(\n",
    "            price.get_text()\n",
    "                .strip()\n",
    "        )\n",
    "    return lst_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_object_title(bs):\n",
    "    # get the names of all the apartments\n",
    "    lst_name = []\n",
    "    object_titles = bs.find_all(class_=\"listing-name\")\n",
    "    for object_title in object_titles:\n",
    "        lst_name.append(\n",
    "            object_title.get_text()\n",
    "                .strip()\n",
    "        )\n",
    "    return lst_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "furnished --> on Blueground we have only furnished Studios/Apartments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "available_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_availability(bs):\n",
    "    # get the availability of the apartments\n",
    "    lst_availability = []\n",
    "    availability = bs.find_all(class_=\"availability__date\")\n",
    "    for avail in availability:\n",
    "        lst_availability.append(\n",
    "            avail.get_text()\n",
    "                .strip()\n",
    "        )\n",
    "    return lst_availability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We need this for extra work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_to_detail_page(bs, maximus):\n",
    "    url_lst = []\n",
    "    count = 0\n",
    "    while count <= int(maximus):\n",
    "        \n",
    "        # this will get us the link to the detail page\n",
    "        class_with_link = bs.find_all(class_=\"ui-image-carousel\")\n",
    "        # with the [] we can select the elment we want to get\n",
    "        for a in class_with_link[count].find_all('a', href=True):\n",
    "            url_lst.append(a['href'])\n",
    "        count += 1\n",
    "    #print(url_lst)\n",
    "    return url_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the Loop to grab everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/z64xf8615mxbsw25_zldzjnm0000gn/T/ipykernel_1743/3108561906.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_search = df_search.append(df_page, ignore_index=True)\n",
      "/var/folders/yg/z64xf8615mxbsw25_zldzjnm0000gn/T/ipykernel_1743/3108561906.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_search = df_search.append(df_page, ignore_index=True)\n",
      "/var/folders/yg/z64xf8615mxbsw25_zldzjnm0000gn/T/ipykernel_1743/3108561906.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_search = df_search.append(df_page, ignore_index=True)\n",
      "/var/folders/yg/z64xf8615mxbsw25_zldzjnm0000gn/T/ipykernel_1743/3108561906.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_search = df_search.append(df_page, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>property_type</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathroom</th>\n",
       "      <th>price_pcm</th>\n",
       "      <th>title</th>\n",
       "      <th>furnished</th>\n",
       "      <th>available_from</th>\n",
       "      <th>get_url_to_detail_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blueground</td>\n",
       "      <td>Soho</td>\n",
       "      <td>Bedroom</td>\n",
       "      <td>1 Bedroom</td>\n",
       "      <td>1 Bath</td>\n",
       "      <td>3,980</td>\n",
       "      <td>Bateman St,</td>\n",
       "      <td>furnished</td>\n",
       "      <td>30 May 2023</td>\n",
       "      <td>/furnished-apartments-london-uk/london-soho-088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blueground</td>\n",
       "      <td>Mayfair</td>\n",
       "      <td>Studio</td>\n",
       "      <td>Studio</td>\n",
       "      <td>1 Bath</td>\n",
       "      <td>3,500</td>\n",
       "      <td>Green St,</td>\n",
       "      <td>furnished</td>\n",
       "      <td>01 Jun 2023</td>\n",
       "      <td>/furnished-apartments-london-uk/london-mayfair-094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blueground</td>\n",
       "      <td>Fitzrovia</td>\n",
       "      <td>Bedroom</td>\n",
       "      <td>2 Bedroom</td>\n",
       "      <td>1.5 Bath</td>\n",
       "      <td>4,430</td>\n",
       "      <td>Tottenham Court Rd,</td>\n",
       "      <td>furnished</td>\n",
       "      <td>02 Jun 2023</td>\n",
       "      <td>/furnished-apartments-london-uk/london-fitzrovia-063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blueground</td>\n",
       "      <td>Old Street</td>\n",
       "      <td>Bedroom</td>\n",
       "      <td>1 Bedroom</td>\n",
       "      <td>1 Bath</td>\n",
       "      <td>4,500</td>\n",
       "      <td>City Rd,</td>\n",
       "      <td>furnished</td>\n",
       "      <td>02 Jun 2023</td>\n",
       "      <td>/furnished-apartments-london-uk/london-old-street-125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blueground</td>\n",
       "      <td>Canary Wharf</td>\n",
       "      <td>Bedroom</td>\n",
       "      <td>2 Bedroom</td>\n",
       "      <td>2 Bath</td>\n",
       "      <td>4,630</td>\n",
       "      <td>Baltimore Wharf,</td>\n",
       "      <td>furnished</td>\n",
       "      <td>03 Jun 2023</td>\n",
       "      <td>/furnished-apartments-london-uk/london-canary-wharf-133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     platform  neighbourhood property_type   bedrooms  bathroom price_pcm  \\\n",
       "0  blueground           Soho       Bedroom  1 Bedroom    1 Bath     3,980   \n",
       "1  blueground        Mayfair        Studio     Studio    1 Bath     3,500   \n",
       "2  blueground      Fitzrovia       Bedroom  2 Bedroom  1.5 Bath     4,430   \n",
       "3  blueground     Old Street       Bedroom  1 Bedroom    1 Bath     4,500   \n",
       "4  blueground   Canary Wharf       Bedroom  2 Bedroom    2 Bath     4,630   \n",
       "\n",
       "                 title  furnished available_from  \\\n",
       "0          Bateman St,  furnished    30 May 2023   \n",
       "1            Green St,  furnished    01 Jun 2023   \n",
       "2  Tottenham Court Rd,  furnished    02 Jun 2023   \n",
       "3             City Rd,  furnished    02 Jun 2023   \n",
       "4     Baltimore Wharf,  furnished    03 Jun 2023   \n",
       "\n",
       "                                    get_url_to_detail_page  \n",
       "0          /furnished-apartments-london-uk/london-soho-088  \n",
       "1       /furnished-apartments-london-uk/london-mayfair-094  \n",
       "2     /furnished-apartments-london-uk/london-fitzrovia-063  \n",
       "3    /furnished-apartments-london-uk/london-old-street-125  \n",
       "4  /furnished-apartments-london-uk/london-canary-wharf-133  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://flexiple.com/python/check-if-list-is-empty-python/\n",
    "# Solution 3: Using len() function\n",
    "# The len() function returns the number of items in a list. If the list is empty, it returns 0.\n",
    "while len(blank_slates_lst) == 0: # start and endpoint of the for-loop\n",
    "    # pause the loop for 3 seconds to reduce the load on the server\n",
    "    time.sleep(3)\n",
    "\n",
    "\n",
    "    # get the content of the website\n",
    "    page = requests.get(weblink +  f'offset={ pagesite }&items=18')\n",
    "    # parse the html and save it into a BeautifulSoup instance\n",
    "    html = page.content\n",
    "    bs = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # create a pandas dataframe for the names and prices\n",
    "    blueground_dict = {\n",
    "        #'platform_id', --> we get this from the detail page\n",
    "        'platform': 'blueground',\n",
    "        'neighbourhood': get_neighborhoods(bs),\n",
    "        'property_type': get_property_type(bs),\n",
    "        'bedrooms': get_bedrooms(bs),\n",
    "        'bathroom': get_bathroom(bs),\n",
    "        'price_pcm': get_price_pcm(bs),\n",
    "        'title': get_object_title(bs),\n",
    "        'furnished': 'furnished',\t\n",
    "        'available_from': get_availability(bs),\n",
    "        #'size': , --> we get this from the detail page\n",
    "        'title': get_object_title(bs)\n",
    "        }\n",
    "\n",
    "    # we now have a dataframe, we can use this to get a counter for the URL\n",
    "    df_page = pd.DataFrame(blueground_dict)\n",
    "\n",
    "    # we create a variable to store the number of rows in the dataframe\n",
    "    maximus = df_page.index.max() # we give it the max value of the index\n",
    "\n",
    "    # we create a list to store the urls\n",
    "    # we check if we reached the end of the existing df, to stop and not get an error\n",
    "    if np.isnan(maximus):\n",
    "        break\n",
    "    else:\n",
    "        df_page['get_url_to_detail_page'] = pd.Series(get_url_to_detail_page(bs, maximus))\n",
    "    # we can now add the dataframe to the full dataframe\n",
    "    df_search = df_search.append(df_page, ignore_index=True)\n",
    "    \n",
    "    # check if we reached the end of the pages\n",
    "    blank_slates = bs.find_all(class_=\"blank-slate__criteria\")\n",
    "    blank_slates_lst = (blank_slate.get_text() for blank_slate in blank_slates)\n",
    "    blank_slates_lst = [blank_slate.strip() for blank_slate in blank_slates_lst]\n",
    "    # print the list to make sure it works\n",
    "    #print(blank_slates_lst)\n",
    "\n",
    "    # increase the pagesite by 1\n",
    "    pagesite += 1\n",
    "\n",
    "# set the number of rows and column_width  to maximum\n",
    "pd.set_option('display.max_rows', None) \n",
    "pd.set_option('display.max_colwidth', None)\n",
    "display(df_search.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a .csv file with the current date and time\n",
    "today = dt.datetime.today().strftime('%Y-%m-%d-%H-%M')\n",
    "df_search.to_csv('data/bluebround_{}.csv'.format(today), sep='\\t')\n",
    "print(\"we have saved the new dataframe in a .csv file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we have to use the URL from the first dataframe to get some details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.theblueground.com/furnished-apartments-london-uk/london-soho-088\n"
     ]
    }
   ],
   "source": [
    "# set up the link for the detail-page\n",
    "\n",
    "\n",
    "weblink_detail = 'https://www.theblueground.com'\n",
    "#pagesite_detail = \"/furnished-apartments-london-uk/london-bayswater-046\"\n",
    "pagesite_with_df = df_search.loc[0, 'get_url_to_detail_page']\n",
    "\n",
    "print(weblink_detail + pagesite_with_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(weblink_detail +  f'{ pagesite_with_df }')\n",
    "# parse the html and save it into a BeautifulSoup instance\n",
    "html = page.content\n",
    "bs = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/furnished-apartments-london-uk/london-soho-088'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_search.loc[0, 'get_url_to_detail_page']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('nf_bs4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9af5746f41ef31dea01f09ffb6ba9bd116b901566dc69a02f72533c94f316243"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
