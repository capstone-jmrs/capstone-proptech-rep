{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spotahome main table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all libraries that are needed\n",
    "\n",
    "import requests                 # requests on websites\n",
    "from bs4 import BeautifulSoup   # html parsing\n",
    "\n",
    "import pandas as pd             # pandas for data frame\n",
    "\n",
    "import math                     # for math methods\n",
    "import time                     # for sleep timer\n",
    "\n",
    "from sql_functions import *     # functions from file for upload on schema\n",
    "import psycopg2                 # for upload on engine\n",
    "\n",
    "import datetime as dt           # for the csv file with the current date and time\n",
    "\n",
    "# libraries that are not needed right now\n",
    "import re\n",
    "#import json\n",
    "#import numpy as np\n",
    "#from zipfile import *\n",
    "\n",
    "\n",
    "# declaration of functions to get specific information from the website\n",
    "\n",
    "# Creating a function to get all the descriptions\n",
    "def get_description(bs):\n",
    "    # find all the descriptions and save them to an empty list\n",
    "    lst_name = []\n",
    "    descriptions = bs.find_all(\n",
    "        class_='homecard-content__title__HomecardContent___OmV4c homecard-content__title--rebranding-style__HomecardContent___OmV4c')\n",
    "    # iterate over the descriptions to get the text and strip the strings and save them in a list\n",
    "    for description in descriptions:\n",
    "        lst_name.append(\n",
    "            description.get_text()\n",
    "                .strip()\n",
    "        )\n",
    "    return lst_name\n",
    "\n",
    "\n",
    "# Creating a function to get all the housing types\n",
    "def get_housing(bs):\n",
    "    # find all the housing types and save them to an empty list\n",
    "    lst_name = []\n",
    "    housings = bs.find_all(\n",
    "        class_='homecard-content__type__HomecardContent___OmV4c homecard-content__type--rebranding-style__HomecardContent___OmV4c')\n",
    "    # iterate over the housing types to get the text and strip the strings and save them in a list\n",
    "    for housing in housings:\n",
    "        lst_name.append(\n",
    "            housing.get_text()\n",
    "                .strip()\n",
    "        )\n",
    "    return lst_name\n",
    "\n",
    "\n",
    "# Creating a function to get all the available dates\n",
    "def get_available(bs):\n",
    "    # find all the available dates and save them to an empty list\n",
    "    lst_name = []\n",
    "    availables = bs.find_all(\n",
    "        class_='homecard-content__available-from__HomecardContent___OmV4c homecard-content__available-from--rebranding-style__HomecardContent___OmV4c')\n",
    "    # iterate over the available appartements to get the text and strip the string and save them in a list\n",
    "    for available in availables:\n",
    "        lst_name.append(\n",
    "            available.get_text()\n",
    "                .strip()\n",
    "                .replace('From ', '')\n",
    "        )\n",
    "    return lst_name\n",
    "\n",
    "\n",
    "# Creating a function to get all the prices\n",
    "def get_price(bs):\n",
    "    # find all the prices and save them to an empty list\n",
    "    lst_name = []\n",
    "    prices = bs.find_all(class_='price__Price___OmV4c')\n",
    "    # iterate over the prices to get the text and strip the strings and save them in a list\n",
    "    for price in prices:\n",
    "        lst_name.append(\n",
    "            price.get_text()\n",
    "                .strip()\n",
    "                .replace('Â£', '')\n",
    "                .split('-')[0]\n",
    "        )\n",
    "    return lst_name\n",
    "\n",
    "\n",
    "# Creating a function to get all the prices per period\n",
    "def get_prices_period(bs):\n",
    "    # find all the aprices per period and save them to an empty list\n",
    "    lst_name = []\n",
    "    prices_period = bs.find_all(\n",
    "        class_='price-monthly__Price___OmV4c price-monthly--rebranding-style__Price___OmV4c')\n",
    "    # iterate over the prices per period to get the text and strip the string and save them in a list\n",
    "    for price_period in prices_period:\n",
    "        lst_name.append(\n",
    "            price_period.get_text()\n",
    "                .strip()\n",
    "                .replace('/', '')\n",
    "        )\n",
    "    return lst_name\n",
    "\n",
    "\n",
    "# Creating a function to get all the ID's\n",
    "def get_ids(bs):\n",
    "    # find all the prices and save them to an empty list\n",
    "    lst_name = []\n",
    "    ids = bs.find_all(class_='l-list__item')\n",
    "    # iterate over the prices to get the text and strip the strings and save them in a list\n",
    "    for id in ids:\n",
    "        lst_name.append(\n",
    "            id.get('data-homecard-scroll')\n",
    "                .strip()\n",
    "        )\n",
    "    return lst_name\n",
    "\n",
    "\n",
    "# Create dictionary in which every location ID gets assigned a location name\n",
    "location_dict = {219: 'Lambeth',\n",
    "                 231: 'Hammersmith and Fulham',\n",
    "                 232: 'Kensington and Chelsea',\n",
    "                 233: 'City of Westminster',\n",
    "                 234: 'Camden',\n",
    "                 235: 'Tower Hamlets',\n",
    "                 236: 'Islington',\n",
    "                 237: 'Hackney',\n",
    "                 241: 'City of London'\n",
    "                 }\n",
    "\n",
    "\n",
    "# Creating a function to get the search result from all pages\n",
    "# the website spotahome shows 60 search results per page. To iterate trough all the pages, we get the information how many search results are there, then divide it by 60 and round it up to get the number of pages.\n",
    "def page_results(property_type, location):\n",
    "    # get the url from the website with the property type and the location as a variable to iterate trough it\n",
    "    page = requests.get(\n",
    "        f'https://www.spotahome.com/s/london--uk/for-rent:{property_type}?areaId[]={location}')\n",
    "    html = page.content\n",
    "    bs = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # Extracting the total number of search results\n",
    "    results = bs.find_all('h1', {'class': 'search-title__title'})\n",
    "\n",
    "    # define the variable result_text in case the first search gives us no results\n",
    "    result_text = 0\n",
    "\n",
    "    # iterate over the results to get the text and strip the string\n",
    "    for result in results:\n",
    "        result_text = result.find(\"strong\").get_text().strip()\n",
    "\n",
    "    # convert the extracted string to an integer to perform mathematical operations\n",
    "    result_converted = int(result_text)\n",
    "\n",
    "    # divide the converted result by 60 since one pages shows 60 results and round it up to get the number of pages\n",
    "    page_site = result_converted / 60\n",
    "    page_site = math.ceil(page_site)\n",
    "\n",
    "    # convert the number of pages from a float to an integer to iterate trough the pages\n",
    "    page_converted = int(page_site)\n",
    "\n",
    "    # create an empty data frame to store the results from every loop cycle\n",
    "    df_search = pd.DataFrame()\n",
    "\n",
    "    # split the url to get access to the part where the page is definde\n",
    "    begin = f'https://www.spotahome.com/s/london--uk/for-rent:{property_type}'\n",
    "    end = f'?areaId[]={location}'\n",
    "\n",
    "    # range is including in the beginning and excluding in the end so we add plus 1 to iterate through all calculated pages\n",
    "    page_converted = page_converted + 1\n",
    "\n",
    "    # for loop to get the page numbers\n",
    "    for page_number in range(page_converted):\n",
    "        # sleep timer to reduce the traffic for the server\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        # get the url from the website with the property type, the location and the page number as a variable to iterate trough it\n",
    "        # middle =\n",
    "        page = requests.get(begin+f'/page:{page_number}'+end)\n",
    "        html = page.content\n",
    "        bs = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        # Create a dictionary to store the results from every loop cycle.\n",
    "        # The keys are the column names and the values are the functions we created before.\n",
    "        # The functions are called with the beautiful soup object as a parameter.\n",
    "        spotahome_dict = {\n",
    "            'platform_id': get_ids(bs),\n",
    "            'platform': 'spotahome',\n",
    "            'neighborhood': location_dict[location],\n",
    "            'property_type': property_type,\n",
    "            'housing_type': get_housing(bs),\n",
    "            'price_pcm': get_price(bs),\n",
    "            'title': get_description(bs),\n",
    "            'furnished': 'furnished',\n",
    "            'available_from': get_available(bs),\n",
    "        }\n",
    "        # the ditionary is stored in a dataframe\n",
    "        df_page = pd.DataFrame(data=spotahome_dict)\n",
    "\n",
    "        # the temporary data frame gets appended to the data frame we created earlier outside the for loop\n",
    "        # for every iteration, the data frame page stores the results in the data frame search\n",
    "        #df_search = df_search.append(df_page)\n",
    "        df_search = pd.concat([df_search, df_page], axis=0, ignore_index=True)\n",
    "    # the data frame search gets returned to the for loop to access it outside the function\n",
    "    return (df_search)\n",
    "\n",
    "\n",
    "# creating a list with different property types given from the website\n",
    "property_types = ['studios', 'apartments/bedrooms:1',\n",
    "                  'apartments/bedrooms:2', 'apartments/bedrooms:3', 'apartments/bedrooms:3more']\n",
    "# creating a list with the different location IDs given from the website\n",
    "locations = [219, 231, 232, 233, 234, 235, 236, 237, 241]\n",
    "\n",
    "# creating an empty data frame\n",
    "df_complete = pd.DataFrame()\n",
    "# for loop to get the different property types\n",
    "for property_type in property_types:\n",
    "    # for loop to get the different locations\n",
    "    for location in locations:\n",
    "        # append the result from data frame search by calling the function page_results with the property type and the location as a parameter to data frame complete\n",
    "        df_complete = pd.concat([df_complete, page_results(\n",
    "            property_type, location)], axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the data frame\n",
    "display(df_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get information about the data frame\n",
    "# results for 5 different property types and 9 different locations with 60 search results per page is 844 on 22.09.2022 10:00 h\n",
    "df_complete.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## details splitted in separate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_details_complete = pd.DataFrame()\n",
    "\n",
    "for idx, row in df_complete.iterrows():\n",
    "    time.sleep(0.5)\n",
    "    page = f\"https://www.spotahome.com/london/for-rent:{row['housing_type'].lower() + 's'}/{row['platform_id']}\"\n",
    "    website = requests.get(page)\n",
    "    results = BeautifulSoup(website.content, 'html.parser')\n",
    "\n",
    "    details = results.find(\n",
    "        'div', class_='property-title__details').find_all('span')\n",
    "\n",
    "    details_lst = (detail.get_text() for detail in details)\n",
    "    details_lst = [detail.strip() for detail in details_lst]\n",
    "\n",
    "    details_lst.pop(0)\n",
    "\n",
    "    details_lst = [i.split(' ', 1) for i in details_lst]\n",
    "\n",
    "    row_dict = {}\n",
    "\n",
    "    for value_key_tuple in details_lst:\n",
    "        new_key_value = {'id': row['platform_id']}\n",
    "        row_dict.update(new_key_value)\n",
    "        key = value_key_tuple[1]\n",
    "        value = value_key_tuple[0]\n",
    "        row_dict[key] = value\n",
    "\n",
    "    df_details = pd.DataFrame(data=row_dict, index=[0])\n",
    "    df_details_complete = pd.concat([df_details_complete, df_details])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_details_complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# export to DBeaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data frame to DBeaver\n",
    "\n",
    "# call the schema created for this project\n",
    "schema = 'capstone_jmrs'\n",
    "# get the function to connect to the database\n",
    "engine = get_engine()\n",
    "\n",
    "# give the table a unique name\n",
    "table_name = 'spotahome_df_complete'\n",
    "\n",
    "# import the table to sql\n",
    "if engine!=None:\n",
    "    try:\n",
    "        df_complete.to_sql(name=table_name,\n",
    "                        con=engine,\n",
    "                        if_exists='replace',\n",
    "                        schema=schema, \n",
    "                        index=False,\n",
    "                        chunksize=5000, \n",
    "                        method='multi')\n",
    "        print(f\"The {table_name} table was imported successfully.\")\n",
    "    \n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        engine = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data frame to DBeaver\n",
    "\n",
    "# call the schema created for this project\n",
    "schema = 'capstone_jmrs'\n",
    "# get the function to connect to the database\n",
    "engine = get_engine()\n",
    "\n",
    "# give the table a unique name\n",
    "table_name = 'spotahome_df_details_complete'\n",
    "\n",
    "# import the table to sql\n",
    "if engine!=None:\n",
    "    try:\n",
    "        df_details_complete.to_sql(name=table_name,\n",
    "                        con=engine,\n",
    "                        if_exists='replace',\n",
    "                        schema=schema, \n",
    "                        index=False,\n",
    "                        chunksize=5000, \n",
    "                        method='multi')\n",
    "        print(f\"The {table_name} table was imported successfully.\")\n",
    "    \n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        engine = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spotahome table for every detail page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_details(bs):\n",
    "#     details = bs.find_all(class_='property-title__details')\n",
    "#     details_lst = (detail.get_text() for detail in details)\n",
    "#     details_lst = [detail.strip() for detail in details_lst]\n",
    "#     return details_lst\n",
    "\n",
    "\n",
    "# df_details = pd.DataFrame()\n",
    "\n",
    "# for idx, row in df_complete.iterrows():\n",
    "#     page=requests.get(\n",
    "#         f\"https://www.spotahome.com/london/for-rent:{row['housing_type'].lower() + 's'}/{row['platform_id']}\")\n",
    "#     html=page.content\n",
    "#     bs=BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "#     details_dict={\n",
    "#         'id': row['platform_id'],\n",
    "#         'housing': row['housing_type'].lower() + 's',\n",
    "#         'details': get_details(bs),\n",
    "#     }\n",
    "#     df_url_housing_id=pd.DataFrame(data=details_dict)\n",
    "#     df_details=pd.concat(\n",
    "#         [df_details, df_url_housing_id], axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# import re\n",
    "# import pandas as pd\n",
    "\n",
    "\n",
    "# def get_details(page):\n",
    "#     website = requests.get(page)\n",
    "#     results = BeautifulSoup(website.content, 'html.parser')\n",
    "\n",
    "#     details = results.find(\n",
    "#         'div', class_='property-title__details').find_all('span')\n",
    "\n",
    "#     details_lst = (detail.get_text() for detail in details)\n",
    "#     details_lst = [detail.strip() for detail in details_lst]\n",
    "\n",
    "#     details_lst.pop(0)\n",
    "\n",
    "#     details_lst = [i.split(' ', 1) for i in details_lst]\n",
    "\n",
    "#     row_dict = {}\n",
    "\n",
    "#     for value_key_tuple in details_lst:\n",
    "#         new_key_value = {'id': row['platform_id']}\n",
    "#         row_dict.update(new_key_value)\n",
    "#         key = value_key_tuple[1]\n",
    "#         value = value_key_tuple[0]\n",
    "#         row_dict[key] = value\n",
    "\n",
    "#     return row_dict\n",
    "\n",
    "\n",
    "# df_details_complete = pd.DataFrame()\n",
    "\n",
    "# for idx, row in df_complete.iterrows():\n",
    "#     page = f\"https://www.spotahome.com/london/for-rent:{row['housing_type'].lower() + 's'}/{row['platform_id']}\"\n",
    "#     website = requests.get(page)\n",
    "#     results = BeautifulSoup(website.content, 'html.parser')\n",
    "\n",
    "#     df_details = pd.DataFrame(get_details(page), index=[0])\n",
    "#     df_details_complete = pd.concat([df_details_complete, df_details])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test code for one property - NOT WORKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_details(bs):\n",
    "#     lst_name = []\n",
    "#     details = bs.find_all(class_='property-title__details')\n",
    "#     for detail in details:\n",
    "#         lst_name.append(\n",
    "#             details.get_text()\n",
    "#                 .strip()\n",
    "#         )\n",
    "#     return lst_name\n",
    "\n",
    "\n",
    "# def get_details_strong(bs):\n",
    "#     lst_name = []\n",
    "#     details_strong = bs.find_all(class_='property-title__details')\n",
    "#     for detail_strong in details_strong:\n",
    "#         lst_name.append(\n",
    "#             details_strong.get('strong').strip()\n",
    "#         )\n",
    "#     return lst_name\n",
    "\n",
    "# page = requests.get(\n",
    "#     'https://www.spotahome.com/london/for-rent:apartments/604187')\n",
    "# html = page.content\n",
    "# bs = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# details_dict = {\n",
    "#     'details': get_details(bs),\n",
    "#     'details_only_int': get_details_strong(bs)\n",
    "# }\n",
    "# df_url_housing_id = pd.DataFrame(data=details_dict)\n",
    "# df_details = pd.concat(\n",
    "#     [df_details, df_url_housing_id], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(df_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test code for all properties with separated information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_details(bs):\n",
    "#     #details = bs.find_all(class_='property-title__details')\n",
    "#     #details_lst = (detail.text.re.compile('m2') for detail in details)\n",
    "#     details = bs.find_all('div', class_='property-title__details').find_all('span')\n",
    "#     details_lst = (detail.get_text() for detail in details)\n",
    "#     details_lst = [detail.strip() for detail in details_lst]\n",
    "#     return details_lst\n",
    "\n",
    "\n",
    "# df_details = pd.DataFrame()\n",
    "\n",
    "# for idx, row in df_complete.iterrows():\n",
    "#     page = requests.get(\n",
    "#         f\"https://www.spotahome.com/london/for-rent:{row['housing_type'].lower() + 's'}/{row['platform_id']}\")\n",
    "#     html = page.content\n",
    "#     bs = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "#     details_dict = {\n",
    "#         #'id': row['platform_id'],\n",
    "#         #'housing': row['housing_type'].lower() + 's',\n",
    "#         'details': get_details(bs),\n",
    "#     }\n",
    "#     df_url_housing_id = pd.DataFrame(data=details_dict)\n",
    "#     df_details = pd.concat(\n",
    "#         [df_details, df_url_housing_id], axis=0, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(df_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a .csv file with the current date and time\n",
    "# today = dt.datetime.today().strftime('%Y-%m-%d-%H-%M')\n",
    "# df_complete.to_csv('spotahome_{}.csv'.format(today), sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('nf_sql')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a81d278bed5b5b59425dcb5a82ce505657686243c184b4a6b67e69d01c4d432e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
