{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping\n",
    "\n",
    "### Web Scraping Best Practices:\n",
    "\n",
    "- Never scrape more frequently than you need to.\n",
    "- Consider caching the content you scrape so that it’s only downloaded once.\n",
    "- Build pauses into your code using functions like time.sleep() to keep from overwhelming servers with too many requests too quickly.\n",
    "- Video von [neuefische](https://www.youtube.com/watch?v=HMSe8WTNmFg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoup\n",
    "\n",
    "The library we will use today to find fishes we can gift Larissa for christmas is [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/). It is a library to extract data out of HTML and XML files.\n",
    "\n",
    "The first thing we’ll need to do to scrape a web page is to download the page. We can download pages using the Python requests.\n",
    "\n",
    "The requests library will make a GET request to a web server, which will download the HTML contents of a given web page for us. There are several different types of requests we can make using requests, of which GET is just one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Blueground - robots.txt\n",
    "User-agent: *  <br>\n",
    "Disallow: /book <br>\n",
    "Disallow: /book-failed<br>\n",
    "Disallow: /book-thankyou<br>\n",
    "Disallow: /expired<br>\n",
    "Disallow: /feedback<br>\n",
    "Disallow: /guests<br>\n",
    "Disallow: /nps<br>\n",
    "Disallow: /offers<br>\n",
    "Disallow: /payment-failed<br>\n",
    "Disallow: /payment-thankyou<br>\n",
    "Disallow: /payments<br>\n",
    "Disallow: /rating<br>\n",
    "Disallow: /users<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/ist.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/lon.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/par.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/vie.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/dxb.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/mia.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/nyc.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/sfo.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/lax.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/bos.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/wdc.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/chi.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/sea.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/den.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/atx.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/zrh.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/ber.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/mad.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/bcn.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/lis.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/bsl.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/hkg.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/cph.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/lux.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/sgp.xml<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the content of the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the content of the website\n",
    "# Blueground - London\n",
    "# https://www.theblueground.com/furnished-apartments-london-uk\n",
    "# page = requests.get(\"https://www.theblueground.com/furnished-apartments-london-uk\")\n",
    "# html = page.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "weblink = 'https://www.theblueground.com/furnished-apartments-london-uk?currency=GBP&language=en&'\n",
    "pagesite = 10 # we take number 10 to test the code\n",
    "page = requests.get(weblink +  f'offset={ pagesite }&items=18')\n",
    "html = page.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the BeautifulSoup library to parse this document, and extract the information from it.\n",
    "\n",
    "We first have to import the library, and create an instance of the BeautifulSoup class to parse our document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the html and save it into a BeautifulSoup instance\n",
    "bs = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now print out the HTML content of the page, formatted nicely, using the prettify method on the BeautifulSoup object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(bs.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if we have more than one element with the same tag? Then we can just use the ```.find_all()``` method of BeautifulSoup:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching for the Apartment/Studio Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Harbour Wy.,', 'Bateman St,', 'Green St,', 'Tottenham Court Rd,', 'City Rd,']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the list of all the apartments\n",
    "object_names = bs.find_all(class_=\"listing-name\")\n",
    "object_names_lst = (object_name.get_text() for object_name in object_names)\n",
    "object_names_lst = [object_name.strip() for object_name in object_names_lst]\n",
    "object_names_lst[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking for the neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Harbour Wy., Canary Wharf',\n",
       " 'Bateman St, Soho',\n",
       " 'Green St, Mayfair',\n",
       " 'Tottenham Court Rd, Fitzrovia',\n",
       " 'City Rd, Old Street']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighborhood_names = bs.find_all(\"div\", {\"class\":\"name-place\"})\n",
    "neighborhood_names_lst = (neighborhood_name.get_text() for neighborhood_name in neighborhood_names)\n",
    "neighborhood_names_lst = [neighborhood_name.strip() for neighborhood_name in neighborhood_names_lst]\n",
    "neighborhood_names_lst[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Canary Wharf', ' Soho', ' Mayfair', ' Fitzrovia', ' Old Street']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighborhood_names = bs.find_all(\"div\", {\"class\":\"name-place\"})\n",
    "neighborhood_names_lst = (neighborhood_name.get_text() for neighborhood_name in neighborhood_names)\n",
    "neighborhood_names_lst = [neighborhood_name.strip() for neighborhood_name in neighborhood_names_lst]\n",
    "neighborhood_names_lst = [i.rsplit(',', 1)[-1] for i in neighborhood_names_lst]\n",
    "neighborhood_names_lst[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harbour Wy., Canary Wharf  \n",
      "Bateman St, Soho  \n",
      "Green St, Mayfair  \n",
      "Tottenham Court Rd, Fitzrovia  \n",
      "City Rd, Old Street  \n",
      "Baltimore Wharf, Canary Wharf  \n",
      "Dock St, Whitechapel/Brick Lane  \n",
      "Haymarket, Piccadilly  \n",
      "Marsh Wall, S Quay Square, Canary Wharf  \n",
      "St George Wharf, Vauxhall  \n",
      "Fitzroy Square, Fitzrovia  \n",
      "Macklin St, Covent Garden  \n",
      "Lower Marsh, Waterloo  \n",
      "Farringdon Rd, Clerkenwell  \n",
      "Cavell St, Whitechapel/Brick Lane  \n",
      "Peninsula Apartments, Praed Street, Paddington  \n"
     ]
    }
   ],
   "source": [
    "soup = bs\n",
    "result = soup.find_all(\"div\", {\"class\":\"name-place\"})\n",
    "\n",
    "for res in result:\n",
    "    print(res.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### availabe - Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the availabe - tag\n",
    "available_tags = bs.find_all(class_=\"availability__available\")\n",
    "available_tag_lst = (available_tag.get_text() for available_tag in available_tags)\n",
    "available_tag_lst = [available_tag.strip() for available_tag in available_tag_lst]\n",
    "available_tag_lst[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### available from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the availabe from information\n",
    "availables = bs.find_all(class_=\"availability__date\")\n",
    "available_lst = (available.get_text() for available in availables)\n",
    "available_lst = [available.strip() for available in available_lst]\n",
    "available_lst[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### price - currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the price__currency\n",
    "price_currencys = bs.find_all(class_= \"price__currency\")\n",
    "price_currencys_lst = [price_currency.get_text() for price_currency in price_currencys]\n",
    "price_currencys_lst = [price_currency.strip() for price_currency in price_currencys_lst]\n",
    "price_currencys_lst[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### price - amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the price amount\n",
    "prices = bs.find_all(class_= \"price__amount\")\n",
    "prices_lst = [price.get_text() for price in prices]\n",
    "prices_lst = [price.strip() for price in prices_lst]\n",
    "prices_lst[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### price per month etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the price per month tag\n",
    "prices_month = bs.find_all(class_= \"monthly-price__suffix monthly-price__suffix--mobile\")\n",
    "prices_month_lst = [price_month.get_text() for price_month in prices_month]\n",
    "prices_month_lst = [price_month.strip() for price_month in prices_month_lst]\n",
    "prices_month_lst = [price_month.replace('/', '') for price_month in prices_month_lst]\n",
    "prices_month_lst = [price_month.replace('mo', 'month') for price_month in prices_month_lst]\n",
    "prices_month_lst[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### complett description of the appartement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2 Bedroom2 Bath 30th Floor | Gym | Doorman',\n",
       " '1 Bedroom1 Bath 3rd Floor',\n",
       " 'Studio1 Bath Lower Ground Floor',\n",
       " '2 Bedroom1.5 Bath City view | 1st, 2nd Floor | Pets allowed',\n",
       " '1 Bedroom1 Bath City view | 2nd Floor | Pool',\n",
       " '2 Bedroom2 Bath City view | 15th Floor | Gym',\n",
       " '1 Bedroom1 Bath City view | 3rd Floor | Gym',\n",
       " 'Jr. 1 Bedroom1 Bath City view | 4th Floor | Elevator']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the description of the apartments\n",
    "descriptions= bs.find_all(class_=\"listing-amenities\")\n",
    "descriptions_lst = [description.get_text() for description in descriptions]\n",
    "descriptions_lst = [description.strip() for description in descriptions_lst]\n",
    "descriptions_lst[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### look for property_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main-amenities  of the appartement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bedroom',\n",
       " 'Bedroom',\n",
       " 'Studio',\n",
       " 'Bedroom',\n",
       " 'Bedroom',\n",
       " 'Bedroom',\n",
       " 'Bedroom',\n",
       " 'Bedroom']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedrooms = bs.find_all(class_=\"main-amenities\")\n",
    "bedrooms_lst = [bedroom.get_text() for bedroom in bedrooms]\n",
    "bedrooms_lst = [bedroom.strip() for bedroom in bedrooms_lst]\n",
    "bedrooms_lst = [i.split('o', 1)[0] for i in bedrooms_lst]\n",
    "bedrooms_lst = [i.replace('Bedr', 'Bedroom') for i in bedrooms_lst]\n",
    "bedrooms_lst = [i.replace('Studi', 'Studio') for i in bedrooms_lst]\n",
    "bedrooms_lst = [i.rsplit(' ', 1)[-1] for i in bedrooms_lst]\n",
    "#bedrooms_lst = [i.replace('Bedroom', 'Apartment') for i in bedrooms_lst]\n",
    "bedrooms_lst[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bedroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2 Bedroom',\n",
       " '1 Bedroom',\n",
       " 'Studi',\n",
       " '2 Bedroom',\n",
       " '1 Bedroom',\n",
       " '2 Bedroom',\n",
       " '1 Bedroom',\n",
       " 'Jr. 1 Bedroom']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the main-amenities of the apartments\n",
    "main_amenities= bs.find_all(class_=\"main-amenities\")\n",
    "main_amenities_lst = [main_amenitie.get_text() for main_amenitie in main_amenities]\n",
    "main_amenities_lst = [main_amenitie.strip() for main_amenitie in main_amenities_lst]\n",
    "main_amenities_lst = [i.split('o', 1)[0] for i in main_amenities_lst]\n",
    "main_amenities_lst = [i.replace('Bedr', 'Bedroom') for i in main_amenities_lst]\n",
    "main_amenities_lst[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bathroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2 Bath', '1 Bath', '1 Bath', '1.5 Bath', '1 Bath', '2 Bath', '1 Bath']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the main-amenities of the apartments\n",
    "main_amenities= bs.find_all(class_=\"main-amenities\")\n",
    "main_amenities_lst = [main_amenitie.get_text() for main_amenitie in main_amenities]\n",
    "main_amenities_lst = [main_amenitie.strip() for main_amenitie in main_amenities_lst]\n",
    "main_amenities_lst = [i.rsplit('o', 1)[-1] for i in main_amenities_lst]\n",
    "main_amenities_lst = [i.replace('m', '') for i in main_amenities_lst]\n",
    "main_amenities_lst[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main_amenities_amenity seperated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2 Bedroom', '1 Bath', '1 Bedroom', '1 Bath', '1 Bedroom']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the main-amenities of the apartments seperated\n",
    "main_amenities_amenitys = bs.find_all(class_=\"main-amenities__amenity\")\n",
    "main_amenities_amenity_lst = [main_amenitie_amenity.get_text() for main_amenitie_amenity in main_amenities_amenitys]\n",
    "main_amenities_amenity_lst = [main_amenitie_amenity.strip() for main_amenitie_amenity in main_amenities_amenity_lst]\n",
    "main_amenities_amenity_lst[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_amenities_amenity_lst = [main_amenitie.strip() for main_amenitie in main_amenities_amenity_lst]\n",
    "# main_amenities_amenity_lst[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rest_amenities of apartment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['City view | 1st Floor | Pets allowed',\n",
       " '7th Floor | Gym | Elevator',\n",
       " '2nd Floor | Balcony',\n",
       " 'City view | 3rd Floor | Pets allowed',\n",
       " '1st, 2nd Floor | Fireplace | Pets allowed']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the rest of the amenities\n",
    "rest_amenities = bs.find_all(class_=\"rest-amenities\")\n",
    "rest_amenities_lst = [rest_amenity.get_text() for rest_amenity in rest_amenities]\n",
    "rest_amenities_lst = [rest_amenity.strip() for rest_amenity in rest_amenities_lst]\n",
    "rest_amenities_lst[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the hyperlink from the website to the detail-side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will get all the elements of the class \"ui-image-carousel\"\n",
    "results = bs.find_all(class_=\"ui-image-carousel\")\n",
    "# we will look for the element a\n",
    "find_a= results[0].find_all('a')\n",
    "print(find_a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will give us all the links of the website\n",
    "soup = bs\n",
    "\n",
    "for a in soup.find_all('a', href=True):\n",
    "    print(\"Found the URL:\", a['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### how to find the link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/furnished-apartments-london-uk/london-canary-wharf-165\n"
     ]
    }
   ],
   "source": [
    "# this will get us the link to the detail page\n",
    "class_with_link = bs.find_all(class_=\"ui-image-carousel\")\n",
    "# with the [] we can select the elment we want to get\n",
    "for a in class_with_link[0].find_all('a', href=True):\n",
    "    url = a['href']\n",
    "    #print(\"Found the URL:\", a['href'])\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/furnished-apartments-london-uk/london-canary-wharf-165']\n"
     ]
    }
   ],
   "source": [
    "url_lst = []\n",
    "# this will get us the link to the detail page\n",
    "class_with_link = bs.find_all(class_=\"ui-image-carousel\")\n",
    "# with the [] we can select the elment we want to get\n",
    "for a in class_with_link[0].find_all('a', href=True):\n",
    "    url_lst.append(a['href'])\n",
    "    #print(\"Found the URL:\", a['href'])\n",
    "print(url_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/furnished-apartments-london-uk/london-canary-wharf-165']\n"
     ]
    }
   ],
   "source": [
    "url_lst = []\n",
    "\n",
    "#count = df.index.max()\n",
    "\n",
    "\n",
    "# this will get us the link to the detail page\n",
    "class_with_link = bs.find_all(class_=\"ui-image-carousel\")\n",
    "# with the [] we can select the elment we want to get\n",
    "for a in class_with_link[count].find_all('a', href=True):\n",
    "    url_lst.append(a['href'])\n",
    "    #print(\"Found the URL:\", a['href'])\n",
    "print(url_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['642044', '642049', '806735', '619186', '642015']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.spotahome.com/s/london--uk/for-rent:apartments/for-rent:studios/bedrooms:3?features[]=pets&noDeposit=1')\n",
    "html = page.content\n",
    "bs = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "ids = bs.find_all(class_ = 'l-list__item')\n",
    "ids_lst = [id.get('data-homecard-scroll') for id in ids]\n",
    "\n",
    "ids_lst[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/markussteinke/neuefische/capstone-ukio-rep/blueground_workbook_markus.ipynb Cell 46\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/markussteinke/neuefische/capstone-ukio-rep/blueground_workbook_markus.ipynb#X60sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m url_lst \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/markussteinke/neuefische/capstone-ukio-rep/blueground_workbook_markus.ipynb#X60sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/markussteinke/neuefische/capstone-ukio-rep/blueground_workbook_markus.ipynb#X60sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mwhile\u001b[39;00m count \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mmax():\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/markussteinke/neuefische/capstone-ukio-rep/blueground_workbook_markus.ipynb#X60sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/markussteinke/neuefische/capstone-ukio-rep/blueground_workbook_markus.ipynb#X60sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m# this will get us the link to the detail page\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/markussteinke/neuefische/capstone-ukio-rep/blueground_workbook_markus.ipynb#X60sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     class_with_link \u001b[39m=\u001b[39m bs\u001b[39m.\u001b[39mfind_all(class_\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mui-image-carousel\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/markussteinke/neuefische/capstone-ukio-rep/blueground_workbook_markus.ipynb#X60sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m# with the [] we can select the elment we want to get\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "url_lst = []\n",
    "count = 0\n",
    "while count <= df.index.max():\n",
    "    \n",
    "    # this will get us the link to the detail page\n",
    "    class_with_link = bs.find_all(class_=\"ui-image-carousel\")\n",
    "    # with the [] we can select the elment we want to get\n",
    "    for a in class_with_link[count].find_all('a', href=True):\n",
    "        url_lst.append(a['href'])\n",
    "    count += 1\n",
    "print(url_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erstellen eines DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['object_name'] = pd.Series(object_names_lst)\n",
    "df['available_tag'] = pd.Series(available_tag_lst)\n",
    "#df['available'] = pd.Series(available_lst)\n",
    "#df['description'] = pd.Series(descriptions_lst)\n",
    "#df['main_amenities'] = pd.Series(main_amenities_lst)\n",
    "#df['main_amenities_amenity'] =pd.Series( main_amenities_amenity_lst)\n",
    "#df['rest_amenities'] = pd.Series(rest_amenities_lst)\n",
    "#df['price_currencys'] = pd.Series(price_currencys_lst)\n",
    "#df['prices'] = pd.Series(prices_lst)\n",
    "#df['prices_month'] = pd.Series(prices_month_lst)\n",
    "df['detail_links'] = pd.Series(url_lst)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = df.index\n",
    "print(index.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the actual DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = dt.datetime.today().strftime('%Y-%m-%d %H:%M') # to set the date in the csv filename\n",
    "df.to_csv('blueground_{}.csv'.format(today), sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information to get data in a loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "look for 'class=\"blank-slate__criteria\"' , this will show us the last page of the infinite-scroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link = 'https://www.theblueground.com/furnished-apartments-london-uk?currency=GBP&language=en&\n",
    "# for _ in range(7):\n",
    "#     time.sleep(3)\n",
    "#     if _ == 0:\n",
    "#         page = requests.get(link + offset=1&items=18)\n",
    "#         html = page.content\n",
    "#     else:\n",
    "#         print(link + f'/offset={_}&items=18')\n",
    "#         page = requests.get(link + f'/offset={_}&items=18')\n",
    "#         html = page.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weblink = 'https://www.theblueground.com/furnished-apartments-london-uk?currency=GBP&language=en&'\n",
    "pagesite = 1\n",
    "\n",
    "while bs.find_all(class_=(\"blank-slate__criteria\")) == False:\n",
    "    time.sleep(5)\n",
    "    page = requests.get(weblink +  f'offset={ pagesite }&items=18')\n",
    "    html = page.content\n",
    "    bs = BeautifulSoup(html, 'html.parser')\n",
    "    print(weblink + f'/offset={ pagesite }&items=18')\n",
    "    pagesite += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will give us the correct url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weblink = 'https://www.theblueground.com/furnished-apartments-london-uk?currency=GBP&language=en&'\n",
    "pagesite = 1\n",
    "\n",
    "while pagesite < 7:\n",
    "    #time.sleep(5)\n",
    "    #page = requests.get(weblink +  f'/offset={ pagesite }&items=18')\n",
    "    #html = page.content\n",
    "    #bs = BeautifulSoup(html, 'html.parser')\n",
    "    print(weblink + f'offset={ pagesite }&items=18')\n",
    "    pagesite += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Website not found:\n",
    "\n",
    "https://www.theblueground.com/furnished-apartments-london-uk?currency=GBP&language=en&offset=18&items=18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the content of the website\n",
    "# Blueground - London\n",
    "# https://www.theblueground.com/furnished-apartments-london-uk\n",
    "page_not_found = requests.get(\"https://www.theblueground.com/furnished-apartments-london-uk?currency=GBP&language=en&offset=15&items=18\")\n",
    "html_not_found = page_not_found.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the html and save it into a BeautifulSoup instance\n",
    "bs_not_found = BeautifulSoup(html_not_found, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank_slates = bs_not_found.find_all(class_=\"blank-slate__criteria\")\n",
    "\n",
    "blank_slates_lst = (blank_slate.get_text() for blank_slate in blank_slates)\n",
    "blank_slates_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank_slates_lst = [blank_slate.strip() for blank_slate in blank_slates_lst]\n",
    "blank_slates_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We try to shop the loop with 'class=\"blank-slate__criteria\"' to see, if we have reached the end of the infinite-scroll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with an Inifiy - Website - Scrolling\n",
    "\n",
    "https://medium.com/@harshvb7/scraping-from-a-website-with-infinite-scrolling-7e080ea8768e\n",
    "\n",
    "https://stackoverflow.com/questions/69046183/how-do-i-scrape-a-website-with-an-infinite-scroller\n",
    "\n",
    "https://stackoverflow.com/questions/64527791/scraping-an-infinite-scroll-page\n",
    "\n",
    "https://stackoverflow.com/questions/12519074/scrape-websites-with-infinite-scrolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weblink = 'https://www.theblueground.com/furnished-apartments-london-uk?currency=GBP&language=en&'\n",
    "pagesite = 12\n",
    "\n",
    "# blank_slates = bs_not_found.find_all(class_=\"blank-slate__criteria\")\n",
    "# blank_slates_lst = (blank_slate.get_text() for blank_slate in blank_slates)\n",
    "# blank_slates_lst\n",
    "# blank_slates_lst = [blank_slate.strip() for blank_slate in blank_slates_lst]\n",
    "blank_slates_lst = []\n",
    "stop_loop = \"We’re sorry! We can’t seem to find any apartments that match your search.\"\n",
    "print(\"Startlink:\", weblink + f'offset={ pagesite }&items=18')\n",
    "print(\"We are looking for:\", stop_loop)\n",
    "print(type(stop_loop))\n",
    "print(\"We currently have:\", blank_slates_lst)\n",
    "print(type(blank_slates_lst))\n",
    "\n",
    "\n",
    "# https://flexiple.com/python/check-if-list-is-empty-python/\n",
    "# Solution 3: Using len() function\n",
    "# The len() function returns the number of items in a list. If the list is empty, it returns 0.\n",
    "while len(blank_slates_lst) == 0:\n",
    "    time.sleep(5)\n",
    "    page = requests.get(weblink +  f'offset={ pagesite }&items=18')\n",
    "    html = page.content\n",
    "    bs_loop = BeautifulSoup(html, 'html.parser')\n",
    "    print(weblink + f'offset={ pagesite }&items=18')\n",
    "    pagesite += 1\n",
    "\n",
    "    blank_slates = bs_loop.find_all(class_=\"blank-slate__criteria\")\n",
    "    blank_slates_lst = (blank_slate.get_text() for blank_slate in blank_slates)\n",
    "    print(blank_slates_lst)\n",
    "    blank_slates_lst = [blank_slate.strip() for blank_slate in blank_slates_lst]\n",
    "    print(blank_slates_lst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pseudo Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#df_full = pd.DataFrame()\n",
    "#df_object = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "weblink = 'https://www.theblueground.com/furnished-apartments-london-uk?currency=GBP&language=en&'\n",
    "pagesite = 12\n",
    "page = requests.get(weblink +  f'offset={ pagesite }&items=18')\n",
    "html = page.content\n",
    "\n",
    "# parse the html and save it into a BeautifulSoup instance\n",
    "bs = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# get the list of all the apartments\n",
    "object_names = bs.find_all(class_=\"listing-name\")\n",
    "object_names_lst = (object_name.get_text() for object_name in object_names)\n",
    "object_names_lst = [object_name.strip() for object_name in object_names_lst]\n",
    "print(object_names_lst[:5])\n",
    "\n",
    "df_object['object_name'] = pd.Series(object_names_lst)\n",
    "df_full = pd.concat([df_full, df_object], axis=0, ignore_index=True)\n",
    "display(df_full)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining the Loop with a run\n",
    "\n",
    "## this code runs, not editing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the libraries\n",
    "\n",
    "import time # to pause the code\n",
    "import requests # to get the content of the website\n",
    "from bs4 import BeautifulSoup # to parse the html\n",
    "import re # to use regular expressions\n",
    "import pandas as pd # to use pandas\n",
    "import numpy as np # to use numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty dataframe\n",
    "df_full = pd.DataFrame()\n",
    "df_object = pd.DataFrame()\n",
    "df_search = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the link to the website\n",
    "\n",
    "weblink = 'https://www.theblueground.com/furnished-apartments-london-uk?currency=GBP&language=en&'\n",
    "\n",
    "# set up the first page to scrape\n",
    "pagesite = 10 # we set it to 10 to test the code\n",
    "\n",
    "# create an empty list to store the blank slates\n",
    "blank_slates_lst = [] \n",
    "\n",
    "# set the stop condition\n",
    "stop_loop = \"We’re sorry! We can’t seem to find any apartments that match your search.\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://flexiple.com/python/check-if-list-is-empty-python/\n",
    "# Solution 3: Using len() function\n",
    "# The len() function returns the number of items in a list. If the list is empty, it returns 0.\n",
    "while len(blank_slates_lst) == 0: # start and endpoint of the for-loop\n",
    "    # pause the loop for 3 seconds to reduce the load on the server\n",
    "    time.sleep(3)\n",
    "\n",
    "\n",
    "    # get the content of the website\n",
    "    page = requests.get(weblink +  f'offset={ pagesite }&items=18')\n",
    "    # parse the html and save it into a BeautifulSoup instance\n",
    "    html = page.content\n",
    "\n",
    "    # parse the html and save it into a BeautifulSoup instance\n",
    "    bs = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # get the list of all the apartments\n",
    "    object_names = bs.find_all(class_=\"listing-name\")\n",
    "    object_names_lst = (object_name.get_text() for object_name in object_names)\n",
    "    object_names_lst = [object_name.strip() for object_name in object_names_lst]\n",
    "    #print(object_names_lst[:5])\n",
    "\n",
    "    # create an empty dataframe to store the object names\n",
    "    df_object = pd.DataFrame()\n",
    "\n",
    "    # store the object names in the dataframe\n",
    "    df_object['object_name'] = pd.Series(object_names_lst)\n",
    "    df_full = pd.concat([df_full, df_object], axis=0, ignore_index=True)\n",
    "\n",
    "    # drop duplicates\n",
    "    df_full.drop_duplicates(subset=['object_name'], keep='first', inplace=True)\n",
    "\n",
    "    # set the number of rows to display to maximum\n",
    "    pd.set_option('display.max_rows', None)\n",
    "\n",
    "    # display the dataframe from the loop\n",
    "    display(df_full)\n",
    "\n",
    "\n",
    "    # check if we reached the end of the pages\n",
    "    blank_slates = bs.find_all(class_=\"blank-slate__criteria\")\n",
    "    blank_slates_lst = (blank_slate.get_text() for blank_slate in blank_slates)\n",
    "    blank_slates_lst = [blank_slate.strip() for blank_slate in blank_slates_lst]\n",
    "    # print the list to make sure it works\n",
    "    #print(blank_slates_lst)\n",
    "\n",
    "    # increase the pagesite by 1\n",
    "    pagesite += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## here you can start editing again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We now try to create functions to work with the loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### von Markus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the html and save it into a BeautifulSoup instance\n",
    "#bs = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "def get_object_name(bs):\n",
    "    # get the names of all the apartments\n",
    "    lst_name = []\n",
    "    object_names = bs.find_all(class_=\"listing-name\")\n",
    "    for object_name in object_names:\n",
    "        lst_name.append(\n",
    "            object_name.get_text()\n",
    "                .strip()\n",
    "        )\n",
    "    return lst_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_to_detail_page(bs, maximus):\n",
    "    url_lst = []\n",
    "    count = 0\n",
    "    while count <= int(maximus):\n",
    "        \n",
    "        # this will get us the link to the detail page\n",
    "        class_with_link = bs.find_all(class_=\"ui-image-carousel\")\n",
    "        # with the [] we can select the elment we want to get\n",
    "        for a in class_with_link[count].find_all('a', href=True):\n",
    "            url_lst.append(a['href'])\n",
    "        count += 1\n",
    "    #print(url_lst)\n",
    "    return url_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/z64xf8615mxbsw25_zldzjnm0000gn/T/ipykernel_2209/4160004379.py:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_search = df_search.append(df_page, ignore_index=True)\n",
      "/var/folders/yg/z64xf8615mxbsw25_zldzjnm0000gn/T/ipykernel_2209/4160004379.py:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_search = df_search.append(df_page, ignore_index=True)\n",
      "/var/folders/yg/z64xf8615mxbsw25_zldzjnm0000gn/T/ipykernel_2209/4160004379.py:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_search = df_search.append(df_page, ignore_index=True)\n",
      "/var/folders/yg/z64xf8615mxbsw25_zldzjnm0000gn/T/ipykernel_2209/4160004379.py:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_search = df_search.append(df_page, ignore_index=True)\n",
      "/var/folders/yg/z64xf8615mxbsw25_zldzjnm0000gn/T/ipykernel_2209/4160004379.py:60: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_names</th>\n",
       "      <th>get_url_to_detail_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Harbour Wy.,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-canary-wharf-165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bateman St,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-soho-088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Green St,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-mayfair-094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tottenham Court Rd,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-fitzrovia-063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>City Rd,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-old-street-125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Baltimore Wharf,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-canary-wharf-133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dock St,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-whitechapel-brick-lane-182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Haymarket,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-piccadilly-036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Marsh Wall, S Quay Square,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-canary-wharf-139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>St George Wharf,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-vauxhall-130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Fitzroy Square,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-fitzrovia-068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Macklin St,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-covent-garden-211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Lower Marsh,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-waterloo-104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Farringdon Rd,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-clerkenwell-095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cavell St,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-whitechapel-brick-lane-169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Peninsula Apartments, Praed Street,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-paddington-181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Lower Marsh,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-waterloo-103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Lower Marsh,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-waterloo-101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Cleveland St,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-fitzrovia-078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Skyline Apartments, Gillender St,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-bromley-by-bow-238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>St Quintin Ave,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-ladbroke-grove-076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Lower Marsh,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-waterloo-102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wellington Street,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-covent-garden-022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Nottingham Pl,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-marylebone-052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Devonshire St,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-marylebone-136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Bourlet Cl,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-fitzrovia-060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Lillie Rd,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-fulham-146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Villiers St,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-charing-cross-097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>New Drum St,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-whitechapel-brick-lane-160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>The Atlas Building,  City Rd,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-old-street-222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Principal Tower, 2 Principal Place,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-shoreditch-258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Bateman St,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-soho-090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Tottenham Court Rd,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-fitzrovia-141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>S Quay Square,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-canary-wharf-092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Old Brompton Rd,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-kensington-073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Farringdon Rd,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-clerkenwell-147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Whitcomb St,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-piccadilly-061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Walpole House,  Westminster Bridge Rd,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-waterloo-262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Gilbert St,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-mayfair-045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Northburgh St,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-clerkenwell-032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>West Block, Forum Magnum Square,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-waterloo-196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Cavell St,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-whitechapel-brick-lane-145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Notting Hill Gate,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-notting-hill-059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Welbeck St,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-marylebone-048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Newman St,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-fitzrovia-233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Glendower Pl,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-south-kensington-047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Causton Rd,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-highgate-111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Matcham House, Glenthorne Rd,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-hammersmith-205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>21G Milner Square,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-islington-208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Inverness Terrace,</td>\n",
       "      <td>/furnished-apartments-london-uk/london-bayswater-046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              object_names  \\\n",
       "0   Harbour Wy.,                             \n",
       "1   Bateman St,                              \n",
       "2   Green St,                                \n",
       "3   Tottenham Court Rd,                      \n",
       "4   City Rd,                                 \n",
       "5   Baltimore Wharf,                         \n",
       "6   Dock St,                                 \n",
       "7   Haymarket,                               \n",
       "8   Marsh Wall, S Quay Square,               \n",
       "9   St George Wharf,                         \n",
       "10  Fitzroy Square,                          \n",
       "11  Macklin St,                              \n",
       "12  Lower Marsh,                             \n",
       "13  Farringdon Rd,                           \n",
       "14  Cavell St,                               \n",
       "15  Peninsula Apartments, Praed Street,      \n",
       "16  Lower Marsh,                             \n",
       "17  Lower Marsh,                             \n",
       "18  Cleveland St,                            \n",
       "19  Skyline Apartments, Gillender St,        \n",
       "20  St Quintin Ave,                          \n",
       "21  Lower Marsh,                             \n",
       "22  Wellington Street,                       \n",
       "23  Nottingham Pl,                           \n",
       "24  Devonshire St,                           \n",
       "25  Bourlet Cl,                              \n",
       "26  Lillie Rd,                               \n",
       "27  Villiers St,                             \n",
       "28  New Drum St,                             \n",
       "29  The Atlas Building,  City Rd,            \n",
       "30  Principal Tower, 2 Principal Place,      \n",
       "31  Bateman St,                              \n",
       "32  Tottenham Court Rd,                      \n",
       "33  S Quay Square,                           \n",
       "34  Old Brompton Rd,                         \n",
       "35  Farringdon Rd,                           \n",
       "36  Whitcomb St,                             \n",
       "37  Walpole House,  Westminster Bridge Rd,   \n",
       "38  Gilbert St,                              \n",
       "39  Northburgh St,                           \n",
       "40  West Block, Forum Magnum Square,         \n",
       "41  Cavell St,                               \n",
       "42  Notting Hill Gate,                       \n",
       "43  Welbeck St,                              \n",
       "44  Newman St,                               \n",
       "45  Glendower Pl,                            \n",
       "46  Causton Rd,                              \n",
       "47  Matcham House, Glenthorne Rd,            \n",
       "48  21G Milner Square,                       \n",
       "49  Inverness Terrace,                       \n",
       "\n",
       "                                               get_url_to_detail_page  \n",
       "0   /furnished-apartments-london-uk/london-canary-wharf-165            \n",
       "1   /furnished-apartments-london-uk/london-soho-088                    \n",
       "2   /furnished-apartments-london-uk/london-mayfair-094                 \n",
       "3   /furnished-apartments-london-uk/london-fitzrovia-063               \n",
       "4   /furnished-apartments-london-uk/london-old-street-125              \n",
       "5   /furnished-apartments-london-uk/london-canary-wharf-133            \n",
       "6   /furnished-apartments-london-uk/london-whitechapel-brick-lane-182  \n",
       "7   /furnished-apartments-london-uk/london-piccadilly-036              \n",
       "8   /furnished-apartments-london-uk/london-canary-wharf-139            \n",
       "9   /furnished-apartments-london-uk/london-vauxhall-130                \n",
       "10  /furnished-apartments-london-uk/london-fitzrovia-068               \n",
       "11  /furnished-apartments-london-uk/london-covent-garden-211           \n",
       "12  /furnished-apartments-london-uk/london-waterloo-104                \n",
       "13  /furnished-apartments-london-uk/london-clerkenwell-095             \n",
       "14  /furnished-apartments-london-uk/london-whitechapel-brick-lane-169  \n",
       "15  /furnished-apartments-london-uk/london-paddington-181              \n",
       "16  /furnished-apartments-london-uk/london-waterloo-103                \n",
       "17  /furnished-apartments-london-uk/london-waterloo-101                \n",
       "18  /furnished-apartments-london-uk/london-fitzrovia-078               \n",
       "19  /furnished-apartments-london-uk/london-bromley-by-bow-238          \n",
       "20  /furnished-apartments-london-uk/london-ladbroke-grove-076          \n",
       "21  /furnished-apartments-london-uk/london-waterloo-102                \n",
       "22  /furnished-apartments-london-uk/london-covent-garden-022           \n",
       "23  /furnished-apartments-london-uk/london-marylebone-052              \n",
       "24  /furnished-apartments-london-uk/london-marylebone-136              \n",
       "25  /furnished-apartments-london-uk/london-fitzrovia-060               \n",
       "26  /furnished-apartments-london-uk/london-fulham-146                  \n",
       "27  /furnished-apartments-london-uk/london-charing-cross-097           \n",
       "28  /furnished-apartments-london-uk/london-whitechapel-brick-lane-160  \n",
       "29  /furnished-apartments-london-uk/london-old-street-222              \n",
       "30  /furnished-apartments-london-uk/london-shoreditch-258              \n",
       "31  /furnished-apartments-london-uk/london-soho-090                    \n",
       "32  /furnished-apartments-london-uk/london-fitzrovia-141               \n",
       "33  /furnished-apartments-london-uk/london-canary-wharf-092            \n",
       "34  /furnished-apartments-london-uk/london-kensington-073              \n",
       "35  /furnished-apartments-london-uk/london-clerkenwell-147             \n",
       "36  /furnished-apartments-london-uk/london-piccadilly-061              \n",
       "37  /furnished-apartments-london-uk/london-waterloo-262                \n",
       "38  /furnished-apartments-london-uk/london-mayfair-045                 \n",
       "39  /furnished-apartments-london-uk/london-clerkenwell-032             \n",
       "40  /furnished-apartments-london-uk/london-waterloo-196                \n",
       "41  /furnished-apartments-london-uk/london-whitechapel-brick-lane-145  \n",
       "42  /furnished-apartments-london-uk/london-notting-hill-059            \n",
       "43  /furnished-apartments-london-uk/london-marylebone-048              \n",
       "44  /furnished-apartments-london-uk/london-fitzrovia-233               \n",
       "45  /furnished-apartments-london-uk/london-south-kensington-047        \n",
       "46  /furnished-apartments-london-uk/london-highgate-111                \n",
       "47  /furnished-apartments-london-uk/london-hammersmith-205             \n",
       "48  /furnished-apartments-london-uk/london-islington-208               \n",
       "49  /furnished-apartments-london-uk/london-bayswater-046               "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://flexiple.com/python/check-if-list-is-empty-python/\n",
    "# Solution 3: Using len() function\n",
    "# The len() function returns the number of items in a list. If the list is empty, it returns 0.\n",
    "while len(blank_slates_lst) == 0: # start and endpoint of the for-loop\n",
    "    # pause the loop for 3 seconds to reduce the load on the server\n",
    "    time.sleep(3)\n",
    "\n",
    "\n",
    "    # get the content of the website\n",
    "    page = requests.get(weblink +  f'offset={ pagesite }&items=18')\n",
    "    # parse the html and save it into a BeautifulSoup instance\n",
    "    html = page.content\n",
    "    bs = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # create a pandas dataframe for the names and prices\n",
    "    blueground_dict = {\n",
    "        'object_names': get_object_name(bs),\n",
    "        }\n",
    "\n",
    "    # we now have a dataframe, we can use this to get a counter for the URL\n",
    "    df_page = pd.DataFrame(blueground_dict)\n",
    "\n",
    "    # we create a variable to store the number of rows in the dataframe\n",
    "    maximus = df_page.index.max() # we give it the max value of the index\n",
    "\n",
    "\n",
    "    if np.isnan(maximus):\n",
    "        break\n",
    "    else:\n",
    "        df_page['get_url_to_detail_page'] = pd.Series(get_url_to_detail_page(bs, maximus))\n",
    "    # we can now add the dataframe to the full dataframe\n",
    "    df_search = df_search.append(df_page, ignore_index=True)\n",
    "    \n",
    "\n",
    "\n",
    "    # # store the object names in the dataframe\n",
    "    # df_object['object_name'] = pd.Series(object_names_lst)\n",
    "    # df_full = pd.concat([df_full, df_object], axis=0, ignore_index=True)\n",
    "\n",
    "    # # drop duplicates\n",
    "    # df_full.drop_duplicates(subset=['object_name'], keep='first', inplace=True)\n",
    "\n",
    "    # # set the number of rows to display to maximum\n",
    "    # pd.set_option('display.max_rows', None)\n",
    "\n",
    "    # # display the dataframe from the loop\n",
    "    # display(df_full)\n",
    "\n",
    "\n",
    "    # check if we reached the end of the pages\n",
    "    blank_slates = bs.find_all(class_=\"blank-slate__criteria\")\n",
    "    blank_slates_lst = (blank_slate.get_text() for blank_slate in blank_slates)\n",
    "    blank_slates_lst = [blank_slate.strip() for blank_slate in blank_slates_lst]\n",
    "    # print the list to make sure it works\n",
    "    #print(blank_slates_lst)\n",
    "\n",
    "    # increase the pagesite by 1\n",
    "    pagesite += 1\n",
    " \n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "display(df_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.theblueground.com/furnished-apartments-london-uk?currency=GBP&language=en&offset=12&items=18\n"
     ]
    }
   ],
   "source": [
    "weblink = 'https://www.theblueground.com/furnished-apartments-london-uk?currency=GBP&language=en&'\n",
    "pagesite = 12\n",
    "page = requests.get(weblink +  f'offset={ pagesite }&items=18')\n",
    "html = page.content\n",
    "print(weblink +  f'offset={ pagesite }&items=18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the html and save it into a BeautifulSoup instance\n",
    "bs = BeautifulSoup(html, 'html.parser')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('nf_bs4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9af5746f41ef31dea01f09ffb6ba9bd116b901566dc69a02f72533c94f316243"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
