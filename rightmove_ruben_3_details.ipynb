{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import math \n",
    "\n",
    "from sql_functions import *    \n",
    "\n",
    "import psycopg2   \n",
    "\n",
    "import sql_functions as sf\n",
    "from sql_functions import get_dataframe\n",
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rightmove_details table was imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# get list of platform_ids from DBeaver first\n",
    "\n",
    "# schema = 'capstone_jmrs'\n",
    "\n",
    "# sql = f\"\"\"\n",
    "# SELECT platform_id \n",
    "# FROM {schema}.rightmove_3\n",
    "# \"\"\"\n",
    "\n",
    "#df = get_dataframe(sql)\n",
    "#ids = df['platform_id'].tolist()[:10]\n",
    "#------------------------------------------------------------\n",
    "#------------------------------------------------------------\n",
    "\n",
    "\n",
    "ids = df['platform_id'].tolist()\n",
    "\n",
    "#ids = ['127325693', '127366049', '117388061', '127365830'] #for testing purposes only\n",
    "df_details_complete = pd.DataFrame()\n",
    "df_basics_complete = pd.DataFrame()\n",
    "\n",
    "for id in ids:\n",
    "    time.sleep(random.randint(2,6)/10)\n",
    "    \n",
    "    page = requests.get(f\"https://www.rightmove.co.uk/properties/{id}#/?channel=RES_LET\")\n",
    "    html = page.content\n",
    "    bs = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # get details\n",
    "    details = bs.find(\n",
    "        'div', class_='_4hBezflLdgDMdFtURKTWh')\n",
    "    details_lst = (detail.get_text() for detail in details)\n",
    "    details_lst = [detail.strip() for detail in details_lst]\n",
    "\n",
    "    #df_details_complete = pd.DataFrame()\n",
    "    bedrooms, bathrooms, size, property_type = 'NA', 'NA', 'NA', 'NA' \n",
    "    row_dict = {'property_id':id, 'bedrooms': bedrooms, 'bathrooms': bathrooms, 'size': size, 'property_type': property_type}\n",
    "    for detail in details_lst:\n",
    "        if 'TYPE' in detail:\n",
    "            row_dict['property_type'] = detail.removeprefix('PROPERTY TYPE')\n",
    "        elif 'BEDROOMS' in detail:\n",
    "            row_dict['bedrooms'] = detail[-1]\n",
    "        elif 'BATHROOM' in detail:\n",
    "            row_dict['bathrooms'] = detail[-1]\n",
    "        elif 'SIZE' in detail:\n",
    "            row_dict['size'] = re.search(r'\\((.*?)\\)', str(detail)).group(1).removesuffix(' sq. m.').replace(',', '')\n",
    "    \n",
    "    df_details = pd.DataFrame(row_dict, index=[0])    \n",
    "    df_details_complete = pd.concat([df_details_complete, df_details], ignore_index=True)\n",
    "\n",
    "    # get other basic details\n",
    "    basics = bs.find_all(\n",
    "        'div', class_='_2RnXSVJcWbWv4IpBC1Sng6')\n",
    "\n",
    "    basics_lst = (basic.get_text() for basic in basics)\n",
    "    basics_lst = [basic.strip().split(': ') for basic in basics_lst]    #'split'\n",
    "    basics_lst\n",
    "\n",
    "    # convert details_lst to dict\n",
    "    itemDict = {item[0]: item[1] for item in basics_lst}\n",
    "    itemDict['platform_id'] = id\n",
    "\n",
    "    df_basics = pd.DataFrame(itemDict, index=[0])    \n",
    "    df_basics_complete = pd.concat([df_basics_complete, df_basics], ignore_index=True)\n",
    "\n",
    "\n",
    "# drop columns we don't need\n",
    "df_basics_complete.drop(['Deposit', 'Min. Tenancy'], axis=1, inplace=True)\n",
    "\n",
    "# pythonise column names \n",
    "df_basics_complete.columns.values[0:3] = ['available_from', 'let_type', 'furnished']\n",
    "\n",
    "# concatenate both detail DFs\n",
    "new_df = pd.concat([df_details_complete, df_basics_complete], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# import the data frame to DBeaver\n",
    "# call the schema created for this project\n",
    "schema = 'capstone_jmrs'\n",
    "# get the function to connect to the database\n",
    "engine = get_engine()\n",
    "\n",
    "# give the table a unique name\n",
    "table_name = 'rightmove_details'\n",
    "\n",
    "# import the table to sql\n",
    "if engine!=None:\n",
    "    try:\n",
    "        new_df.to_sql(name=table_name,\n",
    "                        con=engine,\n",
    "                        if_exists='replace',\n",
    "                        schema=schema, \n",
    "                        index=False,\n",
    "                        chunksize=5000, \n",
    "                        method='multi')\n",
    "        print(f\"The {table_name} table was imported successfully.\")\n",
    "    \n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        engine = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### end of working code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # doesnt take too long\n",
    "# itemDict = {item[0]: item[1] for item in basics_lst}\n",
    "# itemDict['property_id'] = id\n",
    "\n",
    "# itemDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(32 sq. m.)']"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SIZE from detail page - Works, but what if there is no size?\n",
    "\n",
    "sizes = bs_2.find(\n",
    "    'p', class_='_3vyydJK3KMwn7-s2BEXJAf')\n",
    "\n",
    "sizes_lst = (detail.get_text() for detail in sizes)\n",
    "sizes_lst = [detail.strip() for detail in sizes_lst]\n",
    "\n",
    "# convert string\n",
    "# df['size'] = df['size'].str.removesuffix('sq. m.)').str.replace('(', '').str.replace(',', '')\n",
    "sizes_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PROPERTY TYPEApartment', 'BATHROOMS×1']"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details = bs_2.find(\n",
    "    'div', class_='_4hBezflLdgDMdFtURKTWh')\n",
    "details_lst = (detail.get_text() for detail in details)\n",
    "details_lst = [detail.strip() for detail in details_lst]\n",
    "details_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PROPERTY TYPEApartment', 'BATHROOMS×1']"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Would work, but breaks as soon as there is no size (maybe convert to dictionary first?)\n",
    "page_2 = requests.get(\"https://www.rightmove.co.uk/properties/127325693#/?channel=RES_LET\")\n",
    "html_2 = page_2.content\n",
    "bs_2 = BeautifulSoup(html_2, 'html.parser')\n",
    "\n",
    "\n",
    "# TYPE  -- BEDROOMS -- BATHROOMS -- SIZE\n",
    "details = bs_2.find(\n",
    "    'div', class_='_4hBezflLdgDMdFtURKTWh')\n",
    "details_lst = (detail.get_text() for detail in details)\n",
    "details_lst = [detail.strip() for detail in details_lst]\n",
    "details_lst\n",
    "\n",
    "# Format entries\n",
    "# details_lst[0] = str(details_lst[0]).replace('PROPERTY TYPE', '')\n",
    "# details_lst[1] = str(details_lst[1]).replace('BEDROOMS×', '')\n",
    "# details_lst[2] = str(details_lst[2]).replace('BATHROOMS×', '')\n",
    "# #details_lst[3] = re.search(r'\\((.*?)\\)', str(details_lst[3])).group(1).removesuffix(' sq. m.').replace(',', '')\n",
    "\n",
    "details_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OVERVIEW PAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEEDROOMS - WORKS!\n",
    "bedrooms = [title.text.split('bedroom')[0].strip() for title in bs.findAll('h2', {'class': 'propertyCard-title'})]\n",
    "bedrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TYPE - Working so far!\n",
    "types_lst = [title.text.strip().split()[-1] for title in bs.findAll('h2', {'class': 'propertyCard-title'})]\n",
    "types_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BATHROOMS NOT WORKING AT ALL\n",
    "\n",
    "bathrooms = bs.find_all(class_= \"propertyCard-features\")\n",
    "bathrooms_lst = [bathroom.get_text() for bathroom in bathrooms]\n",
    "bathrooms_lst = list(filter(None, bathrooms_lst)) #delete any empty strings from list\n",
    "bathrooms_lst\n",
    "# # format bathrooms\n",
    "# bathrooms_lst = [bathroom.split('bathroom')[0].strip() for bathroom in bathrooms_lst]\n",
    "# bathrooms_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Date added or reduced\n",
    "dates_edited = [date.text for date in bs.findAll('span', {'class': 'propertyCard-branchSummary-addedOrReduced'})]\n",
    "dates_edited\n",
    "\n",
    "## possibly chec/update price in DB if value='reduced...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detail Code from Julia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sql_functions import get_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = 'capstone_jmrs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = f\"\"\"\n",
    "SELECT * \n",
    "FROM {schema}.rightmove_3\n",
    "\"\"\"\n",
    "\n",
    "df = get_dataframe(sql)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_city = df.query('neighbourhood == \"City of London\"')\n",
    "df_city.head(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('nf_sql')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a81d278bed5b5b59425dcb5a82ce505657686243c184b4a6b67e69d01c4d432e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
